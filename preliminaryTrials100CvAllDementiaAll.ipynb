{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b2c851d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#needs a kernel that can load matplotlib, pandas, numpy (does not need to be a microsim kernel)\n",
    "#if you run this on OSC and the kernel dies as you run it, run the notebook with more than 1 cores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4ed6159b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "pd.set_option('display.max_columns', None)\n",
    "pd.set_option('max_colwidth', None)\n",
    "#pd.set_option('max_rows', None)\n",
    "#pd.set_option('max_columns', None)\n",
    "pd.set_option('display.max_rows', None)\n",
    "pd.options.display.float_format = '{:,.4f}'.format\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ee97e248",
   "metadata": {},
   "outputs": [],
   "source": [
    "#resultsDir = \"/users/PAS2164/deligkaris/MICROSIM/SIMULATIONS/PRELIMINARY-TRIALS-100-CV-ALL-DEMENTIA-ALL\"\n",
    "resultsDir = \"/Users/deligkaris.1/OneDrive - The Ohio State University Wexner Medical Center/MICROSIM/SIMULATIONS/PRELIMINARY-TRIALS-100-CV-ALL-DEMENTIA-ALL\"\n",
    "os.chdir(resultsDir)\n",
    "data=pd.read_csv(\"inputLog.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "37486efe",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>reg</th>\n",
       "      <th>se</th>\n",
       "      <th>pvalue</th>\n",
       "      <th>duration</th>\n",
       "      <th>sampleSize</th>\n",
       "      <th>outcome</th>\n",
       "      <th>analysis</th>\n",
       "      <th>dementiaRisk</th>\n",
       "      <th>cvRisk</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-28.6097</td>\n",
       "      <td>1,130,140.1029</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>3</td>\n",
       "      <td>100</td>\n",
       "      <td>death</td>\n",
       "      <td>logisticRegression-death</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3</td>\n",
       "      <td>100</td>\n",
       "      <td>death</td>\n",
       "      <td>logisticRegression-death</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3</td>\n",
       "      <td>100</td>\n",
       "      <td>death</td>\n",
       "      <td>logisticRegression-death</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3</td>\n",
       "      <td>100</td>\n",
       "      <td>death</td>\n",
       "      <td>logisticRegression-death</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3</td>\n",
       "      <td>100</td>\n",
       "      <td>death</td>\n",
       "      <td>logisticRegression-death</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       reg             se  pvalue  duration  sampleSize outcome  \\\n",
       "0 -28.6097 1,130,140.1029  1.0000         3         100   death   \n",
       "1      NaN            NaN     NaN         3         100   death   \n",
       "2      NaN            NaN     NaN         3         100   death   \n",
       "3      NaN            NaN     NaN         3         100   death   \n",
       "4      NaN            NaN     NaN         3         100   death   \n",
       "\n",
       "                   analysis  dementiaRisk  cvRisk  \n",
       "0  logisticRegression-death        0.0000  0.0000  \n",
       "1  logisticRegression-death        0.0000  0.0000  \n",
       "2  logisticRegression-death        0.0000  0.0000  \n",
       "3  logisticRegression-death        0.0000  0.0000  \n",
       "4  logisticRegression-death        0.0000  0.0000  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#some regression results are nan\n",
    "data.head() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "87d52544",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(600000, 9)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "2dc78458",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(13764, 0.02294)"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#how many regressions returned nan in absolute number and percent wise \n",
    "data[\"reg\"].isna().sum(),data[\"reg\"].isna().sum()/data.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "d55ee30f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>reg</th>\n",
       "      <th>se</th>\n",
       "      <th>pvalue</th>\n",
       "      <th>duration</th>\n",
       "      <th>sampleSize</th>\n",
       "      <th>outcome</th>\n",
       "      <th>analysis</th>\n",
       "      <th>dementiaRisk</th>\n",
       "      <th>cvRisk</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>84069</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3</td>\n",
       "      <td>200</td>\n",
       "      <td>death</td>\n",
       "      <td>logisticRegression-death</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0061</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36083</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3</td>\n",
       "      <td>200</td>\n",
       "      <td>death</td>\n",
       "      <td>logisticRegression-death</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0008</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>591617</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>20</td>\n",
       "      <td>100</td>\n",
       "      <td>deathstroke-mi-dementia-</td>\n",
       "      <td>logisticRegression-deathstroke-mi-dementia-</td>\n",
       "      <td>0.0257</td>\n",
       "      <td>0.0132</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>197394</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>15</td>\n",
       "      <td>1000</td>\n",
       "      <td>deathstroke-mi-</td>\n",
       "      <td>logisticRegression-deathstroke-mi-</td>\n",
       "      <td>0.0002</td>\n",
       "      <td>0.0061</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>124464</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>5</td>\n",
       "      <td>200</td>\n",
       "      <td>deathstroke-mi-</td>\n",
       "      <td>logisticRegression-deathstroke-mi-</td>\n",
       "      <td>0.0002</td>\n",
       "      <td>0.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>136464</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>5</td>\n",
       "      <td>200</td>\n",
       "      <td>deathstroke-mi-</td>\n",
       "      <td>logisticRegression-deathstroke-mi-</td>\n",
       "      <td>0.0002</td>\n",
       "      <td>0.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>220012</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3</td>\n",
       "      <td>100</td>\n",
       "      <td>deathstroke-mi-</td>\n",
       "      <td>logisticRegression-deathstroke-mi-</td>\n",
       "      <td>0.0002</td>\n",
       "      <td>0.0132</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>63619</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>20</td>\n",
       "      <td>100</td>\n",
       "      <td>deathstroke-mi-dementia-</td>\n",
       "      <td>logisticRegression-deathstroke-mi-dementia-</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0026</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>122082</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3</td>\n",
       "      <td>200</td>\n",
       "      <td>deathstroke-mi-dementia-</td>\n",
       "      <td>logisticRegression-deathstroke-mi-dementia-</td>\n",
       "      <td>0.0002</td>\n",
       "      <td>0.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>471644</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>20</td>\n",
       "      <td>100</td>\n",
       "      <td>deathstroke-mi-dementia-</td>\n",
       "      <td>logisticRegression-deathstroke-mi-dementia-</td>\n",
       "      <td>0.0059</td>\n",
       "      <td>0.0132</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>256400</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>5</td>\n",
       "      <td>100</td>\n",
       "      <td>deathstroke-mi-</td>\n",
       "      <td>logisticRegression-deathstroke-mi-</td>\n",
       "      <td>0.0013</td>\n",
       "      <td>0.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>197320</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>15</td>\n",
       "      <td>500</td>\n",
       "      <td>deathstroke-mi-</td>\n",
       "      <td>logisticRegression-deathstroke-mi-</td>\n",
       "      <td>0.0002</td>\n",
       "      <td>0.0061</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>194995</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>10</td>\n",
       "      <td>1000</td>\n",
       "      <td>deathstroke-mi-dementia-</td>\n",
       "      <td>logisticRegression-deathstroke-mi-dementia-</td>\n",
       "      <td>0.0002</td>\n",
       "      <td>0.0061</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>84001</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3</td>\n",
       "      <td>100</td>\n",
       "      <td>death</td>\n",
       "      <td>logisticRegression-death</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0061</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>122557</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>5</td>\n",
       "      <td>1000</td>\n",
       "      <td>deathstroke-mi-dementia-</td>\n",
       "      <td>logisticRegression-deathstroke-mi-dementia-</td>\n",
       "      <td>0.0002</td>\n",
       "      <td>0.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>194951</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>10</td>\n",
       "      <td>1000</td>\n",
       "      <td>deathstroke-mi-dementia-</td>\n",
       "      <td>logisticRegression-deathstroke-mi-dementia-</td>\n",
       "      <td>0.0002</td>\n",
       "      <td>0.0061</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>136053</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3</td>\n",
       "      <td>200</td>\n",
       "      <td>deathstroke-mi-</td>\n",
       "      <td>logisticRegression-deathstroke-mi-</td>\n",
       "      <td>0.0002</td>\n",
       "      <td>0.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>360499</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>5</td>\n",
       "      <td>200</td>\n",
       "      <td>death</td>\n",
       "      <td>logisticRegression-death</td>\n",
       "      <td>0.0059</td>\n",
       "      <td>0.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>362040</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3</td>\n",
       "      <td>100</td>\n",
       "      <td>deathstroke-mi-dementia-</td>\n",
       "      <td>logisticRegression-deathstroke-mi-dementia-</td>\n",
       "      <td>0.0059</td>\n",
       "      <td>0.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>194138</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3</td>\n",
       "      <td>500</td>\n",
       "      <td>deathstroke-mi-dementia-</td>\n",
       "      <td>logisticRegression-deathstroke-mi-dementia-</td>\n",
       "      <td>0.0002</td>\n",
       "      <td>0.0061</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        reg  se  pvalue  duration  sampleSize                   outcome  \\\n",
       "84069   NaN NaN     NaN         3         200                     death   \n",
       "36083   NaN NaN     NaN         3         200                     death   \n",
       "591617  NaN NaN     NaN        20         100  deathstroke-mi-dementia-   \n",
       "197394  NaN NaN     NaN        15        1000           deathstroke-mi-   \n",
       "124464  NaN NaN     NaN         5         200           deathstroke-mi-   \n",
       "136464  NaN NaN     NaN         5         200           deathstroke-mi-   \n",
       "220012  NaN NaN     NaN         3         100           deathstroke-mi-   \n",
       "63619   NaN NaN     NaN        20         100  deathstroke-mi-dementia-   \n",
       "122082  NaN NaN     NaN         3         200  deathstroke-mi-dementia-   \n",
       "471644  NaN NaN     NaN        20         100  deathstroke-mi-dementia-   \n",
       "256400  NaN NaN     NaN         5         100           deathstroke-mi-   \n",
       "197320  NaN NaN     NaN        15         500           deathstroke-mi-   \n",
       "194995  NaN NaN     NaN        10        1000  deathstroke-mi-dementia-   \n",
       "84001   NaN NaN     NaN         3         100                     death   \n",
       "122557  NaN NaN     NaN         5        1000  deathstroke-mi-dementia-   \n",
       "194951  NaN NaN     NaN        10        1000  deathstroke-mi-dementia-   \n",
       "136053  NaN NaN     NaN         3         200           deathstroke-mi-   \n",
       "360499  NaN NaN     NaN         5         200                     death   \n",
       "362040  NaN NaN     NaN         3         100  deathstroke-mi-dementia-   \n",
       "194138  NaN NaN     NaN         3         500  deathstroke-mi-dementia-   \n",
       "\n",
       "                                           analysis  dementiaRisk  cvRisk  \n",
       "84069                      logisticRegression-death        0.0000  0.0061  \n",
       "36083                      logisticRegression-death        0.0000  0.0008  \n",
       "591617  logisticRegression-deathstroke-mi-dementia-        0.0257  0.0132  \n",
       "197394           logisticRegression-deathstroke-mi-        0.0002  0.0061  \n",
       "124464           logisticRegression-deathstroke-mi-        0.0002  0.0000  \n",
       "136464           logisticRegression-deathstroke-mi-        0.0002  0.0000  \n",
       "220012           logisticRegression-deathstroke-mi-        0.0002  0.0132  \n",
       "63619   logisticRegression-deathstroke-mi-dementia-        0.0000  0.0026  \n",
       "122082  logisticRegression-deathstroke-mi-dementia-        0.0002  0.0000  \n",
       "471644  logisticRegression-deathstroke-mi-dementia-        0.0059  0.0132  \n",
       "256400           logisticRegression-deathstroke-mi-        0.0013  0.0000  \n",
       "197320           logisticRegression-deathstroke-mi-        0.0002  0.0061  \n",
       "194995  logisticRegression-deathstroke-mi-dementia-        0.0002  0.0061  \n",
       "84001                      logisticRegression-death        0.0000  0.0061  \n",
       "122557  logisticRegression-deathstroke-mi-dementia-        0.0002  0.0000  \n",
       "194951  logisticRegression-deathstroke-mi-dementia-        0.0002  0.0061  \n",
       "136053           logisticRegression-deathstroke-mi-        0.0002  0.0000  \n",
       "360499                     logisticRegression-death        0.0059  0.0000  \n",
       "362040  logisticRegression-deathstroke-mi-dementia-        0.0059  0.0000  \n",
       "194138  logisticRegression-deathstroke-mi-dementia-        0.0002  0.0061  "
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# nans tend to be small sample sizes (but not always), results from logistic regression \n",
    "data[data[\"reg\"].isna()].sample(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "6e70097a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "100      5354\n",
       "200      3292\n",
       "500      1623\n",
       "1000     1051\n",
       "5000      630\n",
       "10000     614\n",
       "15000     602\n",
       "20000     598\n",
       "Name: sampleSize, dtype: int64"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#if the result is nan, most likely it is a small sample size\n",
    "#but from one 20,000 sample trial I get 200 100 sample trials and 5354/598 is a factor of ~10 so smaller \n",
    "#sample trials less likely (by a factor of ~20) to return nan in regression\n",
    "data[data[\"reg\"].isna()][\"sampleSize\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f52d2b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "data[data[\"reg\"].isna()][\"outcome\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1dd71138",
   "metadata": {},
   "outputs": [],
   "source": [
    "#linear regression did not result in nan\n",
    "data[data[\"reg\"].isna()][\"analysis\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "697c6b4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "data[data[\"reg\"].isna()][\"dementiaRisk\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a276809",
   "metadata": {},
   "outputs": [],
   "source": [
    "data[data[\"reg\"].isna()][\"cvRisk\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d8681c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "#if count() is doing what I think is doing, then small and large cv risks are more likely to return nan \n",
    "#in logistic regression\n",
    "#note the massive 4015 for dementia risk 0.0002 and 0.0061\n",
    "\n",
    "data[data[\"reg\"].isna()].groupby([\"dementiaRisk\",\"cvRisk\"]).count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "383732e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "#from now on keep rows without nan\n",
    "results = data.dropna(axis=0).copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "908b39f4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>reg</th>\n",
       "      <th>se</th>\n",
       "      <th>pvalue</th>\n",
       "      <th>duration</th>\n",
       "      <th>sampleSize</th>\n",
       "      <th>outcome</th>\n",
       "      <th>analysis</th>\n",
       "      <th>dementiaRisk</th>\n",
       "      <th>cvRisk</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>433769</th>\n",
       "      <td>-0.0473</td>\n",
       "      <td>0.1776</td>\n",
       "      <td>0.7899</td>\n",
       "      <td>20</td>\n",
       "      <td>1000</td>\n",
       "      <td>death</td>\n",
       "      <td>logisticRegression-death</td>\n",
       "      <td>0.0059</td>\n",
       "      <td>0.0061</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5572</th>\n",
       "      <td>-0.0238</td>\n",
       "      <td>0.0366</td>\n",
       "      <td>0.5151</td>\n",
       "      <td>15</td>\n",
       "      <td>20000</td>\n",
       "      <td>deathstroke-mi-</td>\n",
       "      <td>logisticRegression-deathstroke-mi-</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>202180</th>\n",
       "      <td>0.1500</td>\n",
       "      <td>0.4410</td>\n",
       "      <td>0.7338</td>\n",
       "      <td>3</td>\n",
       "      <td>1000</td>\n",
       "      <td>_gcp-last</td>\n",
       "      <td>linearRegression-_gcp-last</td>\n",
       "      <td>0.0002</td>\n",
       "      <td>0.0061</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>474610</th>\n",
       "      <td>0.0516</td>\n",
       "      <td>0.0354</td>\n",
       "      <td>0.1454</td>\n",
       "      <td>5</td>\n",
       "      <td>5000</td>\n",
       "      <td>_qalys-sum</td>\n",
       "      <td>linearRegression-_qalys-sum</td>\n",
       "      <td>0.0059</td>\n",
       "      <td>0.0132</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>140161</th>\n",
       "      <td>-0.0160</td>\n",
       "      <td>0.1508</td>\n",
       "      <td>0.9155</td>\n",
       "      <td>3</td>\n",
       "      <td>1000</td>\n",
       "      <td>_gcp-mean</td>\n",
       "      <td>linearRegression-_gcp-mean</td>\n",
       "      <td>0.0002</td>\n",
       "      <td>0.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>422150</th>\n",
       "      <td>0.4521</td>\n",
       "      <td>0.4320</td>\n",
       "      <td>0.2954</td>\n",
       "      <td>3</td>\n",
       "      <td>1000</td>\n",
       "      <td>deathstroke-mi-dementia-</td>\n",
       "      <td>logisticRegression-deathstroke-mi-dementia-</td>\n",
       "      <td>0.0059</td>\n",
       "      <td>0.0026</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>297591</th>\n",
       "      <td>0.0127</td>\n",
       "      <td>0.0419</td>\n",
       "      <td>0.7608</td>\n",
       "      <td>15</td>\n",
       "      <td>20000</td>\n",
       "      <td>_gcp-mean</td>\n",
       "      <td>linearRegression-_gcp-mean</td>\n",
       "      <td>0.0013</td>\n",
       "      <td>0.0026</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>228463</th>\n",
       "      <td>0.4499</td>\n",
       "      <td>0.4802</td>\n",
       "      <td>0.3488</td>\n",
       "      <td>5</td>\n",
       "      <td>200</td>\n",
       "      <td>death</td>\n",
       "      <td>logisticRegression-death</td>\n",
       "      <td>0.0002</td>\n",
       "      <td>0.0132</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>272301</th>\n",
       "      <td>0.0204</td>\n",
       "      <td>0.0401</td>\n",
       "      <td>0.6108</td>\n",
       "      <td>3</td>\n",
       "      <td>15000</td>\n",
       "      <td>_gcp-mean</td>\n",
       "      <td>linearRegression-_gcp-mean</td>\n",
       "      <td>0.0013</td>\n",
       "      <td>0.0008</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>386277</th>\n",
       "      <td>0.2565</td>\n",
       "      <td>0.2171</td>\n",
       "      <td>0.2375</td>\n",
       "      <td>3</td>\n",
       "      <td>10000</td>\n",
       "      <td>deathstroke-mi-dementia-</td>\n",
       "      <td>logisticRegression-deathstroke-mi-dementia-</td>\n",
       "      <td>0.0059</td>\n",
       "      <td>0.0008</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           reg     se  pvalue  duration  sampleSize                   outcome  \\\n",
       "433769 -0.0473 0.1776  0.7899        20        1000                     death   \n",
       "5572   -0.0238 0.0366  0.5151        15       20000           deathstroke-mi-   \n",
       "202180  0.1500 0.4410  0.7338         3        1000                 _gcp-last   \n",
       "474610  0.0516 0.0354  0.1454         5        5000                _qalys-sum   \n",
       "140161 -0.0160 0.1508  0.9155         3        1000                 _gcp-mean   \n",
       "422150  0.4521 0.4320  0.2954         3        1000  deathstroke-mi-dementia-   \n",
       "297591  0.0127 0.0419  0.7608        15       20000                 _gcp-mean   \n",
       "228463  0.4499 0.4802  0.3488         5         200                     death   \n",
       "272301  0.0204 0.0401  0.6108         3       15000                 _gcp-mean   \n",
       "386277  0.2565 0.2171  0.2375         3       10000  deathstroke-mi-dementia-   \n",
       "\n",
       "                                           analysis  dementiaRisk  cvRisk  \n",
       "433769                     logisticRegression-death        0.0059  0.0061  \n",
       "5572             logisticRegression-deathstroke-mi-        0.0000  0.0000  \n",
       "202180                   linearRegression-_gcp-last        0.0002  0.0061  \n",
       "474610                  linearRegression-_qalys-sum        0.0059  0.0132  \n",
       "140161                   linearRegression-_gcp-mean        0.0002  0.0000  \n",
       "422150  logisticRegression-deathstroke-mi-dementia-        0.0059  0.0026  \n",
       "297591                   linearRegression-_gcp-mean        0.0013  0.0026  \n",
       "228463                     logisticRegression-death        0.0002  0.0132  \n",
       "272301                   linearRegression-_gcp-mean        0.0013  0.0008  \n",
       "386277  logisticRegression-deathstroke-mi-dementia-        0.0059  0.0008  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results.sample(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "8195582e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(586236, 9)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "4cb327f5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "100    69646\n",
       "Name: sampleSize, dtype: int64"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results.loc[results[\"sampleSize\"]==100][\"sampleSize\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "655e4264",
   "metadata": {},
   "outputs": [],
   "source": [
    "outcomes=results[\"outcome\"].unique()\n",
    "dementiaRisks=results[\"dementiaRisk\"].unique()\n",
    "cvRisks=results[\"cvRisk\"].unique()\n",
    "sampleSizes=results[\"sampleSize\"].unique()\n",
    "durations=results[\"duration\"].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "dbb26be6",
   "metadata": {},
   "outputs": [],
   "source": [
    "meanReg={}  #dictionary, key depends on outcome, duration and sample size, value is an array with cv=row, dem=column\n",
    "results[\"runMeanReg\"]=np.nan #initialize the running mean regression column in the results dataframe\n",
    "runMeanReg = None #initialize temporary pandas series to store the running mean regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "3e3cee15",
   "metadata": {},
   "outputs": [],
   "source": [
    "#calculate means and running means for regression\n",
    "#it takes a few minutes (but not unreasonably long)\n",
    "for outcome in outcomes:    \n",
    "    for duration in durations:\n",
    "        for sampleSize in sampleSizes:\n",
    "            #initialize array for specific outcome, duration, sample size\n",
    "            meanReg[f\"{outcome},{duration},{sampleSize}\"]=np.zeros((len(cvRisks),len(dementiaRisks)))\n",
    "            for iCvRisk in range(len(cvRisks)):\n",
    "                for iDementiaRisk in range(len(dementiaRisks)):\n",
    "                    dfForParameters=results.loc[ #get all relevant data\n",
    "                                    (results[\"outcome\"]==outcome) & \n",
    "                                    (results[\"sampleSize\"]==sampleSize) &\n",
    "                                    (results[\"dementiaRisk\"]==dementiaRisks[iDementiaRisk]) & \n",
    "                                    (results[\"cvRisk\"]==cvRisks[iCvRisk]) &\n",
    "                                    (results[\"duration\"]==duration) ]\n",
    "                    regs=dfForParameters[\"reg\"].copy() #get regression coefficients only\n",
    "                    meanReg[f\"{outcome},{duration},{sampleSize}\"][iCvRisk,iDementiaRisk]=regs.mean() #store mean\n",
    "                    #calculate and store running mean\n",
    "                    if runMeanReg is None:\n",
    "                        runMeanReg=regs.expanding().mean()\n",
    "                    else:\n",
    "                        runMeanReg=pd.concat([runMeanReg,regs.expanding().mean()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "ea95d25c",
   "metadata": {},
   "outputs": [],
   "source": [
    "results[\"runMeanReg\"]=runMeanReg #store running means in results dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "88c02b63",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>reg</th>\n",
       "      <th>se</th>\n",
       "      <th>pvalue</th>\n",
       "      <th>duration</th>\n",
       "      <th>sampleSize</th>\n",
       "      <th>outcome</th>\n",
       "      <th>analysis</th>\n",
       "      <th>dementiaRisk</th>\n",
       "      <th>cvRisk</th>\n",
       "      <th>runMeanReg</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-28.6097</td>\n",
       "      <td>1,130,140.1029</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>3</td>\n",
       "      <td>100</td>\n",
       "      <td>death</td>\n",
       "      <td>logisticRegression-death</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>-28.6097</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.0000</td>\n",
       "      <td>1.4286</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>3</td>\n",
       "      <td>100</td>\n",
       "      <td>death</td>\n",
       "      <td>logisticRegression-death</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>-14.3048</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>-27.8959</td>\n",
       "      <td>1,130,139.7761</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>3</td>\n",
       "      <td>100</td>\n",
       "      <td>death</td>\n",
       "      <td>logisticRegression-death</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>-18.8352</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>16.9112</td>\n",
       "      <td>4,654.0557</td>\n",
       "      <td>0.9971</td>\n",
       "      <td>3</td>\n",
       "      <td>100</td>\n",
       "      <td>death</td>\n",
       "      <td>logisticRegression-death</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>-9.8986</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0.4265</td>\n",
       "      <td>0.9357</td>\n",
       "      <td>0.6485</td>\n",
       "      <td>3</td>\n",
       "      <td>100</td>\n",
       "      <td>death</td>\n",
       "      <td>logisticRegression-death</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>-7.8336</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       reg             se  pvalue  duration  sampleSize outcome  \\\n",
       "0 -28.6097 1,130,140.1029  1.0000         3         100   death   \n",
       "5   0.0000         1.4286  1.0000         3         100   death   \n",
       "6 -27.8959 1,130,139.7761  1.0000         3         100   death   \n",
       "7  16.9112     4,654.0557  0.9971         3         100   death   \n",
       "9   0.4265         0.9357  0.6485         3         100   death   \n",
       "\n",
       "                   analysis  dementiaRisk  cvRisk  runMeanReg  \n",
       "0  logisticRegression-death        0.0000  0.0000    -28.6097  \n",
       "5  logisticRegression-death        0.0000  0.0000    -14.3048  \n",
       "6  logisticRegression-death        0.0000  0.0000    -18.8352  \n",
       "7  logisticRegression-death        0.0000  0.0000     -9.8986  \n",
       "9  logisticRegression-death        0.0000  0.0000     -7.8336  "
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "ce907f28",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>reg</th>\n",
       "      <th>se</th>\n",
       "      <th>pvalue</th>\n",
       "      <th>duration</th>\n",
       "      <th>sampleSize</th>\n",
       "      <th>outcome</th>\n",
       "      <th>analysis</th>\n",
       "      <th>dementiaRisk</th>\n",
       "      <th>cvRisk</th>\n",
       "      <th>runMeanReg</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>289950</th>\n",
       "      <td>-0.0404</td>\n",
       "      <td>0.0731</td>\n",
       "      <td>0.5802</td>\n",
       "      <td>20</td>\n",
       "      <td>20000</td>\n",
       "      <td>death</td>\n",
       "      <td>logisticRegression-death</td>\n",
       "      <td>0.0013</td>\n",
       "      <td>0.0026</td>\n",
       "      <td>-0.0404</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>289951</th>\n",
       "      <td>0.0301</td>\n",
       "      <td>0.0732</td>\n",
       "      <td>0.6806</td>\n",
       "      <td>20</td>\n",
       "      <td>20000</td>\n",
       "      <td>death</td>\n",
       "      <td>logisticRegression-death</td>\n",
       "      <td>0.0013</td>\n",
       "      <td>0.0026</td>\n",
       "      <td>-0.0051</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>289952</th>\n",
       "      <td>-0.0702</td>\n",
       "      <td>0.0723</td>\n",
       "      <td>0.3317</td>\n",
       "      <td>20</td>\n",
       "      <td>20000</td>\n",
       "      <td>death</td>\n",
       "      <td>logisticRegression-death</td>\n",
       "      <td>0.0013</td>\n",
       "      <td>0.0026</td>\n",
       "      <td>-0.0268</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>289953</th>\n",
       "      <td>0.0736</td>\n",
       "      <td>0.0727</td>\n",
       "      <td>0.3115</td>\n",
       "      <td>20</td>\n",
       "      <td>20000</td>\n",
       "      <td>death</td>\n",
       "      <td>logisticRegression-death</td>\n",
       "      <td>0.0013</td>\n",
       "      <td>0.0026</td>\n",
       "      <td>-0.0017</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>289954</th>\n",
       "      <td>0.0835</td>\n",
       "      <td>0.0730</td>\n",
       "      <td>0.2529</td>\n",
       "      <td>20</td>\n",
       "      <td>20000</td>\n",
       "      <td>death</td>\n",
       "      <td>logisticRegression-death</td>\n",
       "      <td>0.0013</td>\n",
       "      <td>0.0026</td>\n",
       "      <td>0.0153</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>289955</th>\n",
       "      <td>-0.0259</td>\n",
       "      <td>0.0742</td>\n",
       "      <td>0.7268</td>\n",
       "      <td>20</td>\n",
       "      <td>20000</td>\n",
       "      <td>death</td>\n",
       "      <td>logisticRegression-death</td>\n",
       "      <td>0.0013</td>\n",
       "      <td>0.0026</td>\n",
       "      <td>0.0085</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>289956</th>\n",
       "      <td>-0.0387</td>\n",
       "      <td>0.0723</td>\n",
       "      <td>0.5920</td>\n",
       "      <td>20</td>\n",
       "      <td>20000</td>\n",
       "      <td>death</td>\n",
       "      <td>logisticRegression-death</td>\n",
       "      <td>0.0013</td>\n",
       "      <td>0.0026</td>\n",
       "      <td>0.0017</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>289957</th>\n",
       "      <td>-0.0086</td>\n",
       "      <td>0.0729</td>\n",
       "      <td>0.9057</td>\n",
       "      <td>20</td>\n",
       "      <td>20000</td>\n",
       "      <td>death</td>\n",
       "      <td>logisticRegression-death</td>\n",
       "      <td>0.0013</td>\n",
       "      <td>0.0026</td>\n",
       "      <td>0.0004</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>289958</th>\n",
       "      <td>0.0425</td>\n",
       "      <td>0.0719</td>\n",
       "      <td>0.5543</td>\n",
       "      <td>20</td>\n",
       "      <td>20000</td>\n",
       "      <td>death</td>\n",
       "      <td>logisticRegression-death</td>\n",
       "      <td>0.0013</td>\n",
       "      <td>0.0026</td>\n",
       "      <td>0.0051</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>289959</th>\n",
       "      <td>-0.1480</td>\n",
       "      <td>0.0721</td>\n",
       "      <td>0.0401</td>\n",
       "      <td>20</td>\n",
       "      <td>20000</td>\n",
       "      <td>death</td>\n",
       "      <td>logisticRegression-death</td>\n",
       "      <td>0.0013</td>\n",
       "      <td>0.0026</td>\n",
       "      <td>-0.0102</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>289960</th>\n",
       "      <td>-0.0239</td>\n",
       "      <td>0.0714</td>\n",
       "      <td>0.7382</td>\n",
       "      <td>20</td>\n",
       "      <td>20000</td>\n",
       "      <td>death</td>\n",
       "      <td>logisticRegression-death</td>\n",
       "      <td>0.0013</td>\n",
       "      <td>0.0026</td>\n",
       "      <td>-0.0115</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>289961</th>\n",
       "      <td>-0.0127</td>\n",
       "      <td>0.0745</td>\n",
       "      <td>0.8641</td>\n",
       "      <td>20</td>\n",
       "      <td>20000</td>\n",
       "      <td>death</td>\n",
       "      <td>logisticRegression-death</td>\n",
       "      <td>0.0013</td>\n",
       "      <td>0.0026</td>\n",
       "      <td>-0.0116</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>289962</th>\n",
       "      <td>-0.0921</td>\n",
       "      <td>0.0713</td>\n",
       "      <td>0.1962</td>\n",
       "      <td>20</td>\n",
       "      <td>20000</td>\n",
       "      <td>death</td>\n",
       "      <td>logisticRegression-death</td>\n",
       "      <td>0.0013</td>\n",
       "      <td>0.0026</td>\n",
       "      <td>-0.0178</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>289963</th>\n",
       "      <td>0.0314</td>\n",
       "      <td>0.0721</td>\n",
       "      <td>0.6637</td>\n",
       "      <td>20</td>\n",
       "      <td>20000</td>\n",
       "      <td>death</td>\n",
       "      <td>logisticRegression-death</td>\n",
       "      <td>0.0013</td>\n",
       "      <td>0.0026</td>\n",
       "      <td>-0.0143</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>289964</th>\n",
       "      <td>-0.0348</td>\n",
       "      <td>0.0727</td>\n",
       "      <td>0.6319</td>\n",
       "      <td>20</td>\n",
       "      <td>20000</td>\n",
       "      <td>death</td>\n",
       "      <td>logisticRegression-death</td>\n",
       "      <td>0.0013</td>\n",
       "      <td>0.0026</td>\n",
       "      <td>-0.0156</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>289965</th>\n",
       "      <td>-0.0383</td>\n",
       "      <td>0.0730</td>\n",
       "      <td>0.5998</td>\n",
       "      <td>20</td>\n",
       "      <td>20000</td>\n",
       "      <td>death</td>\n",
       "      <td>logisticRegression-death</td>\n",
       "      <td>0.0013</td>\n",
       "      <td>0.0026</td>\n",
       "      <td>-0.0170</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>289966</th>\n",
       "      <td>0.0038</td>\n",
       "      <td>0.0727</td>\n",
       "      <td>0.9586</td>\n",
       "      <td>20</td>\n",
       "      <td>20000</td>\n",
       "      <td>death</td>\n",
       "      <td>logisticRegression-death</td>\n",
       "      <td>0.0013</td>\n",
       "      <td>0.0026</td>\n",
       "      <td>-0.0158</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>289967</th>\n",
       "      <td>-0.0267</td>\n",
       "      <td>0.0719</td>\n",
       "      <td>0.7105</td>\n",
       "      <td>20</td>\n",
       "      <td>20000</td>\n",
       "      <td>death</td>\n",
       "      <td>logisticRegression-death</td>\n",
       "      <td>0.0013</td>\n",
       "      <td>0.0026</td>\n",
       "      <td>-0.0164</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>289968</th>\n",
       "      <td>-0.0211</td>\n",
       "      <td>0.0719</td>\n",
       "      <td>0.7689</td>\n",
       "      <td>20</td>\n",
       "      <td>20000</td>\n",
       "      <td>death</td>\n",
       "      <td>logisticRegression-death</td>\n",
       "      <td>0.0013</td>\n",
       "      <td>0.0026</td>\n",
       "      <td>-0.0167</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>289969</th>\n",
       "      <td>-0.0222</td>\n",
       "      <td>0.0730</td>\n",
       "      <td>0.7614</td>\n",
       "      <td>20</td>\n",
       "      <td>20000</td>\n",
       "      <td>death</td>\n",
       "      <td>logisticRegression-death</td>\n",
       "      <td>0.0013</td>\n",
       "      <td>0.0026</td>\n",
       "      <td>-0.0169</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>289970</th>\n",
       "      <td>0.1665</td>\n",
       "      <td>0.0732</td>\n",
       "      <td>0.0229</td>\n",
       "      <td>20</td>\n",
       "      <td>20000</td>\n",
       "      <td>death</td>\n",
       "      <td>logisticRegression-death</td>\n",
       "      <td>0.0013</td>\n",
       "      <td>0.0026</td>\n",
       "      <td>-0.0082</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>289971</th>\n",
       "      <td>0.1339</td>\n",
       "      <td>0.0711</td>\n",
       "      <td>0.0596</td>\n",
       "      <td>20</td>\n",
       "      <td>20000</td>\n",
       "      <td>death</td>\n",
       "      <td>logisticRegression-death</td>\n",
       "      <td>0.0013</td>\n",
       "      <td>0.0026</td>\n",
       "      <td>-0.0017</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>289972</th>\n",
       "      <td>-0.0917</td>\n",
       "      <td>0.0728</td>\n",
       "      <td>0.2077</td>\n",
       "      <td>20</td>\n",
       "      <td>20000</td>\n",
       "      <td>death</td>\n",
       "      <td>logisticRegression-death</td>\n",
       "      <td>0.0013</td>\n",
       "      <td>0.0026</td>\n",
       "      <td>-0.0057</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>289973</th>\n",
       "      <td>0.0084</td>\n",
       "      <td>0.0731</td>\n",
       "      <td>0.9090</td>\n",
       "      <td>20</td>\n",
       "      <td>20000</td>\n",
       "      <td>death</td>\n",
       "      <td>logisticRegression-death</td>\n",
       "      <td>0.0013</td>\n",
       "      <td>0.0026</td>\n",
       "      <td>-0.0051</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>289974</th>\n",
       "      <td>0.0814</td>\n",
       "      <td>0.0742</td>\n",
       "      <td>0.2720</td>\n",
       "      <td>20</td>\n",
       "      <td>20000</td>\n",
       "      <td>death</td>\n",
       "      <td>logisticRegression-death</td>\n",
       "      <td>0.0013</td>\n",
       "      <td>0.0026</td>\n",
       "      <td>-0.0016</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>289975</th>\n",
       "      <td>0.1156</td>\n",
       "      <td>0.0745</td>\n",
       "      <td>0.1205</td>\n",
       "      <td>20</td>\n",
       "      <td>20000</td>\n",
       "      <td>death</td>\n",
       "      <td>logisticRegression-death</td>\n",
       "      <td>0.0013</td>\n",
       "      <td>0.0026</td>\n",
       "      <td>0.0029</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>289976</th>\n",
       "      <td>0.0787</td>\n",
       "      <td>0.0732</td>\n",
       "      <td>0.2824</td>\n",
       "      <td>20</td>\n",
       "      <td>20000</td>\n",
       "      <td>death</td>\n",
       "      <td>logisticRegression-death</td>\n",
       "      <td>0.0013</td>\n",
       "      <td>0.0026</td>\n",
       "      <td>0.0057</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>289977</th>\n",
       "      <td>-0.0749</td>\n",
       "      <td>0.0747</td>\n",
       "      <td>0.3166</td>\n",
       "      <td>20</td>\n",
       "      <td>20000</td>\n",
       "      <td>death</td>\n",
       "      <td>logisticRegression-death</td>\n",
       "      <td>0.0013</td>\n",
       "      <td>0.0026</td>\n",
       "      <td>0.0028</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>289978</th>\n",
       "      <td>0.0393</td>\n",
       "      <td>0.0736</td>\n",
       "      <td>0.5934</td>\n",
       "      <td>20</td>\n",
       "      <td>20000</td>\n",
       "      <td>death</td>\n",
       "      <td>logisticRegression-death</td>\n",
       "      <td>0.0013</td>\n",
       "      <td>0.0026</td>\n",
       "      <td>0.0041</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>289979</th>\n",
       "      <td>0.0466</td>\n",
       "      <td>0.0751</td>\n",
       "      <td>0.5351</td>\n",
       "      <td>20</td>\n",
       "      <td>20000</td>\n",
       "      <td>death</td>\n",
       "      <td>logisticRegression-death</td>\n",
       "      <td>0.0013</td>\n",
       "      <td>0.0026</td>\n",
       "      <td>0.0055</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>289980</th>\n",
       "      <td>0.0289</td>\n",
       "      <td>0.0735</td>\n",
       "      <td>0.6945</td>\n",
       "      <td>20</td>\n",
       "      <td>20000</td>\n",
       "      <td>death</td>\n",
       "      <td>logisticRegression-death</td>\n",
       "      <td>0.0013</td>\n",
       "      <td>0.0026</td>\n",
       "      <td>0.0063</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>289981</th>\n",
       "      <td>0.0045</td>\n",
       "      <td>0.0723</td>\n",
       "      <td>0.9499</td>\n",
       "      <td>20</td>\n",
       "      <td>20000</td>\n",
       "      <td>death</td>\n",
       "      <td>logisticRegression-death</td>\n",
       "      <td>0.0013</td>\n",
       "      <td>0.0026</td>\n",
       "      <td>0.0062</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>289982</th>\n",
       "      <td>0.0994</td>\n",
       "      <td>0.0747</td>\n",
       "      <td>0.1831</td>\n",
       "      <td>20</td>\n",
       "      <td>20000</td>\n",
       "      <td>death</td>\n",
       "      <td>logisticRegression-death</td>\n",
       "      <td>0.0013</td>\n",
       "      <td>0.0026</td>\n",
       "      <td>0.0090</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>289983</th>\n",
       "      <td>-0.0775</td>\n",
       "      <td>0.0746</td>\n",
       "      <td>0.2988</td>\n",
       "      <td>20</td>\n",
       "      <td>20000</td>\n",
       "      <td>death</td>\n",
       "      <td>logisticRegression-death</td>\n",
       "      <td>0.0013</td>\n",
       "      <td>0.0026</td>\n",
       "      <td>0.0065</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>289984</th>\n",
       "      <td>0.0667</td>\n",
       "      <td>0.0740</td>\n",
       "      <td>0.3673</td>\n",
       "      <td>20</td>\n",
       "      <td>20000</td>\n",
       "      <td>death</td>\n",
       "      <td>logisticRegression-death</td>\n",
       "      <td>0.0013</td>\n",
       "      <td>0.0026</td>\n",
       "      <td>0.0082</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>289985</th>\n",
       "      <td>0.0566</td>\n",
       "      <td>0.0739</td>\n",
       "      <td>0.4433</td>\n",
       "      <td>20</td>\n",
       "      <td>20000</td>\n",
       "      <td>death</td>\n",
       "      <td>logisticRegression-death</td>\n",
       "      <td>0.0013</td>\n",
       "      <td>0.0026</td>\n",
       "      <td>0.0095</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>289986</th>\n",
       "      <td>-0.0374</td>\n",
       "      <td>0.0749</td>\n",
       "      <td>0.6177</td>\n",
       "      <td>20</td>\n",
       "      <td>20000</td>\n",
       "      <td>death</td>\n",
       "      <td>logisticRegression-death</td>\n",
       "      <td>0.0013</td>\n",
       "      <td>0.0026</td>\n",
       "      <td>0.0083</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>289987</th>\n",
       "      <td>-0.0593</td>\n",
       "      <td>0.0756</td>\n",
       "      <td>0.4324</td>\n",
       "      <td>20</td>\n",
       "      <td>20000</td>\n",
       "      <td>death</td>\n",
       "      <td>logisticRegression-death</td>\n",
       "      <td>0.0013</td>\n",
       "      <td>0.0026</td>\n",
       "      <td>0.0065</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>289988</th>\n",
       "      <td>-0.0699</td>\n",
       "      <td>0.0738</td>\n",
       "      <td>0.3437</td>\n",
       "      <td>20</td>\n",
       "      <td>20000</td>\n",
       "      <td>death</td>\n",
       "      <td>logisticRegression-death</td>\n",
       "      <td>0.0013</td>\n",
       "      <td>0.0026</td>\n",
       "      <td>0.0045</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>289989</th>\n",
       "      <td>-0.0330</td>\n",
       "      <td>0.0714</td>\n",
       "      <td>0.6444</td>\n",
       "      <td>20</td>\n",
       "      <td>20000</td>\n",
       "      <td>death</td>\n",
       "      <td>logisticRegression-death</td>\n",
       "      <td>0.0013</td>\n",
       "      <td>0.0026</td>\n",
       "      <td>0.0036</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>289990</th>\n",
       "      <td>0.0695</td>\n",
       "      <td>0.0730</td>\n",
       "      <td>0.3409</td>\n",
       "      <td>20</td>\n",
       "      <td>20000</td>\n",
       "      <td>death</td>\n",
       "      <td>logisticRegression-death</td>\n",
       "      <td>0.0013</td>\n",
       "      <td>0.0026</td>\n",
       "      <td>0.0052</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>289991</th>\n",
       "      <td>0.0623</td>\n",
       "      <td>0.0733</td>\n",
       "      <td>0.3954</td>\n",
       "      <td>20</td>\n",
       "      <td>20000</td>\n",
       "      <td>death</td>\n",
       "      <td>logisticRegression-death</td>\n",
       "      <td>0.0013</td>\n",
       "      <td>0.0026</td>\n",
       "      <td>0.0066</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>289992</th>\n",
       "      <td>-0.0448</td>\n",
       "      <td>0.0697</td>\n",
       "      <td>0.5202</td>\n",
       "      <td>20</td>\n",
       "      <td>20000</td>\n",
       "      <td>death</td>\n",
       "      <td>logisticRegression-death</td>\n",
       "      <td>0.0013</td>\n",
       "      <td>0.0026</td>\n",
       "      <td>0.0054</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>289993</th>\n",
       "      <td>0.1174</td>\n",
       "      <td>0.0737</td>\n",
       "      <td>0.1112</td>\n",
       "      <td>20</td>\n",
       "      <td>20000</td>\n",
       "      <td>death</td>\n",
       "      <td>logisticRegression-death</td>\n",
       "      <td>0.0013</td>\n",
       "      <td>0.0026</td>\n",
       "      <td>0.0079</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>289994</th>\n",
       "      <td>-0.0289</td>\n",
       "      <td>0.0748</td>\n",
       "      <td>0.6991</td>\n",
       "      <td>20</td>\n",
       "      <td>20000</td>\n",
       "      <td>death</td>\n",
       "      <td>logisticRegression-death</td>\n",
       "      <td>0.0013</td>\n",
       "      <td>0.0026</td>\n",
       "      <td>0.0071</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>289995</th>\n",
       "      <td>-0.0184</td>\n",
       "      <td>0.0734</td>\n",
       "      <td>0.8023</td>\n",
       "      <td>20</td>\n",
       "      <td>20000</td>\n",
       "      <td>death</td>\n",
       "      <td>logisticRegression-death</td>\n",
       "      <td>0.0013</td>\n",
       "      <td>0.0026</td>\n",
       "      <td>0.0065</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>289996</th>\n",
       "      <td>0.0662</td>\n",
       "      <td>0.0723</td>\n",
       "      <td>0.3601</td>\n",
       "      <td>20</td>\n",
       "      <td>20000</td>\n",
       "      <td>death</td>\n",
       "      <td>logisticRegression-death</td>\n",
       "      <td>0.0013</td>\n",
       "      <td>0.0026</td>\n",
       "      <td>0.0078</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>289997</th>\n",
       "      <td>-0.0118</td>\n",
       "      <td>0.0725</td>\n",
       "      <td>0.8705</td>\n",
       "      <td>20</td>\n",
       "      <td>20000</td>\n",
       "      <td>death</td>\n",
       "      <td>logisticRegression-death</td>\n",
       "      <td>0.0013</td>\n",
       "      <td>0.0026</td>\n",
       "      <td>0.0074</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>289998</th>\n",
       "      <td>-0.0767</td>\n",
       "      <td>0.0737</td>\n",
       "      <td>0.2981</td>\n",
       "      <td>20</td>\n",
       "      <td>20000</td>\n",
       "      <td>death</td>\n",
       "      <td>logisticRegression-death</td>\n",
       "      <td>0.0013</td>\n",
       "      <td>0.0026</td>\n",
       "      <td>0.0057</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>289999</th>\n",
       "      <td>0.0256</td>\n",
       "      <td>0.0707</td>\n",
       "      <td>0.7172</td>\n",
       "      <td>20</td>\n",
       "      <td>20000</td>\n",
       "      <td>death</td>\n",
       "      <td>logisticRegression-death</td>\n",
       "      <td>0.0013</td>\n",
       "      <td>0.0026</td>\n",
       "      <td>0.0061</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>301950</th>\n",
       "      <td>-0.0273</td>\n",
       "      <td>0.1338</td>\n",
       "      <td>0.8383</td>\n",
       "      <td>20</td>\n",
       "      <td>20000</td>\n",
       "      <td>death</td>\n",
       "      <td>logisticRegression-death</td>\n",
       "      <td>0.0013</td>\n",
       "      <td>0.0026</td>\n",
       "      <td>0.0054</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>301951</th>\n",
       "      <td>-0.1231</td>\n",
       "      <td>0.1427</td>\n",
       "      <td>0.3884</td>\n",
       "      <td>20</td>\n",
       "      <td>20000</td>\n",
       "      <td>death</td>\n",
       "      <td>logisticRegression-death</td>\n",
       "      <td>0.0013</td>\n",
       "      <td>0.0026</td>\n",
       "      <td>0.0030</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>301952</th>\n",
       "      <td>0.0222</td>\n",
       "      <td>0.1421</td>\n",
       "      <td>0.8758</td>\n",
       "      <td>20</td>\n",
       "      <td>20000</td>\n",
       "      <td>death</td>\n",
       "      <td>logisticRegression-death</td>\n",
       "      <td>0.0013</td>\n",
       "      <td>0.0026</td>\n",
       "      <td>0.0033</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>301953</th>\n",
       "      <td>0.1672</td>\n",
       "      <td>0.1287</td>\n",
       "      <td>0.1940</td>\n",
       "      <td>20</td>\n",
       "      <td>20000</td>\n",
       "      <td>death</td>\n",
       "      <td>logisticRegression-death</td>\n",
       "      <td>0.0013</td>\n",
       "      <td>0.0026</td>\n",
       "      <td>0.0064</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>301954</th>\n",
       "      <td>0.0504</td>\n",
       "      <td>0.1286</td>\n",
       "      <td>0.6949</td>\n",
       "      <td>20</td>\n",
       "      <td>20000</td>\n",
       "      <td>death</td>\n",
       "      <td>logisticRegression-death</td>\n",
       "      <td>0.0013</td>\n",
       "      <td>0.0026</td>\n",
       "      <td>0.0072</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>301955</th>\n",
       "      <td>0.0700</td>\n",
       "      <td>0.1322</td>\n",
       "      <td>0.5963</td>\n",
       "      <td>20</td>\n",
       "      <td>20000</td>\n",
       "      <td>death</td>\n",
       "      <td>logisticRegression-death</td>\n",
       "      <td>0.0013</td>\n",
       "      <td>0.0026</td>\n",
       "      <td>0.0083</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>301956</th>\n",
       "      <td>-0.0858</td>\n",
       "      <td>0.1328</td>\n",
       "      <td>0.5181</td>\n",
       "      <td>20</td>\n",
       "      <td>20000</td>\n",
       "      <td>death</td>\n",
       "      <td>logisticRegression-death</td>\n",
       "      <td>0.0013</td>\n",
       "      <td>0.0026</td>\n",
       "      <td>0.0066</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>301957</th>\n",
       "      <td>0.0583</td>\n",
       "      <td>0.1305</td>\n",
       "      <td>0.6548</td>\n",
       "      <td>20</td>\n",
       "      <td>20000</td>\n",
       "      <td>death</td>\n",
       "      <td>logisticRegression-death</td>\n",
       "      <td>0.0013</td>\n",
       "      <td>0.0026</td>\n",
       "      <td>0.0075</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>301958</th>\n",
       "      <td>-0.1058</td>\n",
       "      <td>0.1337</td>\n",
       "      <td>0.4286</td>\n",
       "      <td>20</td>\n",
       "      <td>20000</td>\n",
       "      <td>death</td>\n",
       "      <td>logisticRegression-death</td>\n",
       "      <td>0.0013</td>\n",
       "      <td>0.0026</td>\n",
       "      <td>0.0056</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>301959</th>\n",
       "      <td>-0.1368</td>\n",
       "      <td>0.1302</td>\n",
       "      <td>0.2934</td>\n",
       "      <td>20</td>\n",
       "      <td>20000</td>\n",
       "      <td>death</td>\n",
       "      <td>logisticRegression-death</td>\n",
       "      <td>0.0013</td>\n",
       "      <td>0.0026</td>\n",
       "      <td>0.0032</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>301960</th>\n",
       "      <td>-0.0861</td>\n",
       "      <td>0.1345</td>\n",
       "      <td>0.5221</td>\n",
       "      <td>20</td>\n",
       "      <td>20000</td>\n",
       "      <td>death</td>\n",
       "      <td>logisticRegression-death</td>\n",
       "      <td>0.0013</td>\n",
       "      <td>0.0026</td>\n",
       "      <td>0.0018</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>301961</th>\n",
       "      <td>-0.0776</td>\n",
       "      <td>0.1330</td>\n",
       "      <td>0.5593</td>\n",
       "      <td>20</td>\n",
       "      <td>20000</td>\n",
       "      <td>death</td>\n",
       "      <td>logisticRegression-death</td>\n",
       "      <td>0.0013</td>\n",
       "      <td>0.0026</td>\n",
       "      <td>0.0005</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>301962</th>\n",
       "      <td>-0.0030</td>\n",
       "      <td>0.1387</td>\n",
       "      <td>0.9826</td>\n",
       "      <td>20</td>\n",
       "      <td>20000</td>\n",
       "      <td>death</td>\n",
       "      <td>logisticRegression-death</td>\n",
       "      <td>0.0013</td>\n",
       "      <td>0.0026</td>\n",
       "      <td>0.0004</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>301963</th>\n",
       "      <td>-0.0112</td>\n",
       "      <td>0.1275</td>\n",
       "      <td>0.9302</td>\n",
       "      <td>20</td>\n",
       "      <td>20000</td>\n",
       "      <td>death</td>\n",
       "      <td>logisticRegression-death</td>\n",
       "      <td>0.0013</td>\n",
       "      <td>0.0026</td>\n",
       "      <td>0.0002</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>301964</th>\n",
       "      <td>-0.2569</td>\n",
       "      <td>0.1281</td>\n",
       "      <td>0.0450</td>\n",
       "      <td>20</td>\n",
       "      <td>20000</td>\n",
       "      <td>death</td>\n",
       "      <td>logisticRegression-death</td>\n",
       "      <td>0.0013</td>\n",
       "      <td>0.0026</td>\n",
       "      <td>-0.0037</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>301965</th>\n",
       "      <td>-0.0457</td>\n",
       "      <td>0.1289</td>\n",
       "      <td>0.7226</td>\n",
       "      <td>20</td>\n",
       "      <td>20000</td>\n",
       "      <td>death</td>\n",
       "      <td>logisticRegression-death</td>\n",
       "      <td>0.0013</td>\n",
       "      <td>0.0026</td>\n",
       "      <td>-0.0043</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>301966</th>\n",
       "      <td>0.0626</td>\n",
       "      <td>0.1305</td>\n",
       "      <td>0.6314</td>\n",
       "      <td>20</td>\n",
       "      <td>20000</td>\n",
       "      <td>death</td>\n",
       "      <td>logisticRegression-death</td>\n",
       "      <td>0.0013</td>\n",
       "      <td>0.0026</td>\n",
       "      <td>-0.0033</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>301967</th>\n",
       "      <td>0.1168</td>\n",
       "      <td>0.1291</td>\n",
       "      <td>0.3658</td>\n",
       "      <td>20</td>\n",
       "      <td>20000</td>\n",
       "      <td>death</td>\n",
       "      <td>logisticRegression-death</td>\n",
       "      <td>0.0013</td>\n",
       "      <td>0.0026</td>\n",
       "      <td>-0.0016</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>301968</th>\n",
       "      <td>-0.0953</td>\n",
       "      <td>0.1328</td>\n",
       "      <td>0.4729</td>\n",
       "      <td>20</td>\n",
       "      <td>20000</td>\n",
       "      <td>death</td>\n",
       "      <td>logisticRegression-death</td>\n",
       "      <td>0.0013</td>\n",
       "      <td>0.0026</td>\n",
       "      <td>-0.0029</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>301969</th>\n",
       "      <td>-0.0179</td>\n",
       "      <td>0.1332</td>\n",
       "      <td>0.8932</td>\n",
       "      <td>20</td>\n",
       "      <td>20000</td>\n",
       "      <td>death</td>\n",
       "      <td>logisticRegression-death</td>\n",
       "      <td>0.0013</td>\n",
       "      <td>0.0026</td>\n",
       "      <td>-0.0032</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>301970</th>\n",
       "      <td>0.0592</td>\n",
       "      <td>0.1395</td>\n",
       "      <td>0.6714</td>\n",
       "      <td>20</td>\n",
       "      <td>20000</td>\n",
       "      <td>death</td>\n",
       "      <td>logisticRegression-death</td>\n",
       "      <td>0.0013</td>\n",
       "      <td>0.0026</td>\n",
       "      <td>-0.0023</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>301971</th>\n",
       "      <td>0.0036</td>\n",
       "      <td>0.1302</td>\n",
       "      <td>0.9779</td>\n",
       "      <td>20</td>\n",
       "      <td>20000</td>\n",
       "      <td>death</td>\n",
       "      <td>logisticRegression-death</td>\n",
       "      <td>0.0013</td>\n",
       "      <td>0.0026</td>\n",
       "      <td>-0.0022</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>301972</th>\n",
       "      <td>0.0330</td>\n",
       "      <td>0.1310</td>\n",
       "      <td>0.8008</td>\n",
       "      <td>20</td>\n",
       "      <td>20000</td>\n",
       "      <td>death</td>\n",
       "      <td>logisticRegression-death</td>\n",
       "      <td>0.0013</td>\n",
       "      <td>0.0026</td>\n",
       "      <td>-0.0017</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>301973</th>\n",
       "      <td>-0.1391</td>\n",
       "      <td>0.1221</td>\n",
       "      <td>0.2545</td>\n",
       "      <td>20</td>\n",
       "      <td>20000</td>\n",
       "      <td>death</td>\n",
       "      <td>logisticRegression-death</td>\n",
       "      <td>0.0013</td>\n",
       "      <td>0.0026</td>\n",
       "      <td>-0.0036</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>301974</th>\n",
       "      <td>0.1702</td>\n",
       "      <td>0.1321</td>\n",
       "      <td>0.1976</td>\n",
       "      <td>20</td>\n",
       "      <td>20000</td>\n",
       "      <td>death</td>\n",
       "      <td>logisticRegression-death</td>\n",
       "      <td>0.0013</td>\n",
       "      <td>0.0026</td>\n",
       "      <td>-0.0012</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>301975</th>\n",
       "      <td>0.1310</td>\n",
       "      <td>0.1323</td>\n",
       "      <td>0.3223</td>\n",
       "      <td>20</td>\n",
       "      <td>20000</td>\n",
       "      <td>death</td>\n",
       "      <td>logisticRegression-death</td>\n",
       "      <td>0.0013</td>\n",
       "      <td>0.0026</td>\n",
       "      <td>0.0005</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>301976</th>\n",
       "      <td>-0.0630</td>\n",
       "      <td>0.1336</td>\n",
       "      <td>0.6371</td>\n",
       "      <td>20</td>\n",
       "      <td>20000</td>\n",
       "      <td>death</td>\n",
       "      <td>logisticRegression-death</td>\n",
       "      <td>0.0013</td>\n",
       "      <td>0.0026</td>\n",
       "      <td>-0.0003</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>301977</th>\n",
       "      <td>0.0395</td>\n",
       "      <td>0.1321</td>\n",
       "      <td>0.7647</td>\n",
       "      <td>20</td>\n",
       "      <td>20000</td>\n",
       "      <td>death</td>\n",
       "      <td>logisticRegression-death</td>\n",
       "      <td>0.0013</td>\n",
       "      <td>0.0026</td>\n",
       "      <td>0.0002</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>301978</th>\n",
       "      <td>-0.1369</td>\n",
       "      <td>0.1350</td>\n",
       "      <td>0.3106</td>\n",
       "      <td>20</td>\n",
       "      <td>20000</td>\n",
       "      <td>death</td>\n",
       "      <td>logisticRegression-death</td>\n",
       "      <td>0.0013</td>\n",
       "      <td>0.0026</td>\n",
       "      <td>-0.0016</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>301979</th>\n",
       "      <td>0.2178</td>\n",
       "      <td>0.1293</td>\n",
       "      <td>0.0923</td>\n",
       "      <td>20</td>\n",
       "      <td>20000</td>\n",
       "      <td>death</td>\n",
       "      <td>logisticRegression-death</td>\n",
       "      <td>0.0013</td>\n",
       "      <td>0.0026</td>\n",
       "      <td>0.0012</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>301980</th>\n",
       "      <td>-0.0450</td>\n",
       "      <td>0.1362</td>\n",
       "      <td>0.7409</td>\n",
       "      <td>20</td>\n",
       "      <td>20000</td>\n",
       "      <td>death</td>\n",
       "      <td>logisticRegression-death</td>\n",
       "      <td>0.0013</td>\n",
       "      <td>0.0026</td>\n",
       "      <td>0.0006</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>301981</th>\n",
       "      <td>0.1168</td>\n",
       "      <td>0.1352</td>\n",
       "      <td>0.3879</td>\n",
       "      <td>20</td>\n",
       "      <td>20000</td>\n",
       "      <td>death</td>\n",
       "      <td>logisticRegression-death</td>\n",
       "      <td>0.0013</td>\n",
       "      <td>0.0026</td>\n",
       "      <td>0.0020</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>301982</th>\n",
       "      <td>-0.0184</td>\n",
       "      <td>0.1278</td>\n",
       "      <td>0.8858</td>\n",
       "      <td>20</td>\n",
       "      <td>20000</td>\n",
       "      <td>death</td>\n",
       "      <td>logisticRegression-death</td>\n",
       "      <td>0.0013</td>\n",
       "      <td>0.0026</td>\n",
       "      <td>0.0018</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>301983</th>\n",
       "      <td>-0.0813</td>\n",
       "      <td>0.1316</td>\n",
       "      <td>0.5370</td>\n",
       "      <td>20</td>\n",
       "      <td>20000</td>\n",
       "      <td>death</td>\n",
       "      <td>logisticRegression-death</td>\n",
       "      <td>0.0013</td>\n",
       "      <td>0.0026</td>\n",
       "      <td>0.0008</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>301984</th>\n",
       "      <td>0.0136</td>\n",
       "      <td>0.1344</td>\n",
       "      <td>0.9197</td>\n",
       "      <td>20</td>\n",
       "      <td>20000</td>\n",
       "      <td>death</td>\n",
       "      <td>logisticRegression-death</td>\n",
       "      <td>0.0013</td>\n",
       "      <td>0.0026</td>\n",
       "      <td>0.0009</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>301985</th>\n",
       "      <td>0.0435</td>\n",
       "      <td>0.1324</td>\n",
       "      <td>0.7426</td>\n",
       "      <td>20</td>\n",
       "      <td>20000</td>\n",
       "      <td>death</td>\n",
       "      <td>logisticRegression-death</td>\n",
       "      <td>0.0013</td>\n",
       "      <td>0.0026</td>\n",
       "      <td>0.0014</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>301986</th>\n",
       "      <td>-0.2828</td>\n",
       "      <td>0.1416</td>\n",
       "      <td>0.0458</td>\n",
       "      <td>20</td>\n",
       "      <td>20000</td>\n",
       "      <td>death</td>\n",
       "      <td>logisticRegression-death</td>\n",
       "      <td>0.0013</td>\n",
       "      <td>0.0026</td>\n",
       "      <td>-0.0018</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>301987</th>\n",
       "      <td>-0.3516</td>\n",
       "      <td>0.1267</td>\n",
       "      <td>0.0055</td>\n",
       "      <td>20</td>\n",
       "      <td>20000</td>\n",
       "      <td>death</td>\n",
       "      <td>logisticRegression-death</td>\n",
       "      <td>0.0013</td>\n",
       "      <td>0.0026</td>\n",
       "      <td>-0.0058</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>301988</th>\n",
       "      <td>0.0781</td>\n",
       "      <td>0.1433</td>\n",
       "      <td>0.5859</td>\n",
       "      <td>20</td>\n",
       "      <td>20000</td>\n",
       "      <td>death</td>\n",
       "      <td>logisticRegression-death</td>\n",
       "      <td>0.0013</td>\n",
       "      <td>0.0026</td>\n",
       "      <td>-0.0049</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>301989</th>\n",
       "      <td>-0.2794</td>\n",
       "      <td>0.1304</td>\n",
       "      <td>0.0321</td>\n",
       "      <td>20</td>\n",
       "      <td>20000</td>\n",
       "      <td>death</td>\n",
       "      <td>logisticRegression-death</td>\n",
       "      <td>0.0013</td>\n",
       "      <td>0.0026</td>\n",
       "      <td>-0.0079</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>301990</th>\n",
       "      <td>0.1597</td>\n",
       "      <td>0.1350</td>\n",
       "      <td>0.2367</td>\n",
       "      <td>20</td>\n",
       "      <td>20000</td>\n",
       "      <td>death</td>\n",
       "      <td>logisticRegression-death</td>\n",
       "      <td>0.0013</td>\n",
       "      <td>0.0026</td>\n",
       "      <td>-0.0061</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>301991</th>\n",
       "      <td>-0.2274</td>\n",
       "      <td>0.1358</td>\n",
       "      <td>0.0940</td>\n",
       "      <td>20</td>\n",
       "      <td>20000</td>\n",
       "      <td>death</td>\n",
       "      <td>logisticRegression-death</td>\n",
       "      <td>0.0013</td>\n",
       "      <td>0.0026</td>\n",
       "      <td>-0.0085</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>301992</th>\n",
       "      <td>0.0371</td>\n",
       "      <td>0.1319</td>\n",
       "      <td>0.7782</td>\n",
       "      <td>20</td>\n",
       "      <td>20000</td>\n",
       "      <td>death</td>\n",
       "      <td>logisticRegression-death</td>\n",
       "      <td>0.0013</td>\n",
       "      <td>0.0026</td>\n",
       "      <td>-0.0080</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>301993</th>\n",
       "      <td>0.0057</td>\n",
       "      <td>0.1350</td>\n",
       "      <td>0.9665</td>\n",
       "      <td>20</td>\n",
       "      <td>20000</td>\n",
       "      <td>death</td>\n",
       "      <td>logisticRegression-death</td>\n",
       "      <td>0.0013</td>\n",
       "      <td>0.0026</td>\n",
       "      <td>-0.0078</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>301994</th>\n",
       "      <td>-0.0665</td>\n",
       "      <td>0.1294</td>\n",
       "      <td>0.6071</td>\n",
       "      <td>20</td>\n",
       "      <td>20000</td>\n",
       "      <td>death</td>\n",
       "      <td>logisticRegression-death</td>\n",
       "      <td>0.0013</td>\n",
       "      <td>0.0026</td>\n",
       "      <td>-0.0085</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>301995</th>\n",
       "      <td>0.1523</td>\n",
       "      <td>0.1226</td>\n",
       "      <td>0.2142</td>\n",
       "      <td>20</td>\n",
       "      <td>20000</td>\n",
       "      <td>death</td>\n",
       "      <td>logisticRegression-death</td>\n",
       "      <td>0.0013</td>\n",
       "      <td>0.0026</td>\n",
       "      <td>-0.0068</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>301996</th>\n",
       "      <td>-0.1193</td>\n",
       "      <td>0.1348</td>\n",
       "      <td>0.3765</td>\n",
       "      <td>20</td>\n",
       "      <td>20000</td>\n",
       "      <td>death</td>\n",
       "      <td>logisticRegression-death</td>\n",
       "      <td>0.0013</td>\n",
       "      <td>0.0026</td>\n",
       "      <td>-0.0079</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>301997</th>\n",
       "      <td>-0.0000</td>\n",
       "      <td>0.1302</td>\n",
       "      <td>0.9998</td>\n",
       "      <td>20</td>\n",
       "      <td>20000</td>\n",
       "      <td>death</td>\n",
       "      <td>logisticRegression-death</td>\n",
       "      <td>0.0013</td>\n",
       "      <td>0.0026</td>\n",
       "      <td>-0.0079</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>301998</th>\n",
       "      <td>0.0402</td>\n",
       "      <td>0.1338</td>\n",
       "      <td>0.7641</td>\n",
       "      <td>20</td>\n",
       "      <td>20000</td>\n",
       "      <td>death</td>\n",
       "      <td>logisticRegression-death</td>\n",
       "      <td>0.0013</td>\n",
       "      <td>0.0026</td>\n",
       "      <td>-0.0074</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>301999</th>\n",
       "      <td>-0.0889</td>\n",
       "      <td>0.1282</td>\n",
       "      <td>0.4883</td>\n",
       "      <td>20</td>\n",
       "      <td>20000</td>\n",
       "      <td>death</td>\n",
       "      <td>logisticRegression-death</td>\n",
       "      <td>0.0013</td>\n",
       "      <td>0.0026</td>\n",
       "      <td>-0.0082</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           reg     se  pvalue  duration  sampleSize outcome  \\\n",
       "289950 -0.0404 0.0731  0.5802        20       20000   death   \n",
       "289951  0.0301 0.0732  0.6806        20       20000   death   \n",
       "289952 -0.0702 0.0723  0.3317        20       20000   death   \n",
       "289953  0.0736 0.0727  0.3115        20       20000   death   \n",
       "289954  0.0835 0.0730  0.2529        20       20000   death   \n",
       "289955 -0.0259 0.0742  0.7268        20       20000   death   \n",
       "289956 -0.0387 0.0723  0.5920        20       20000   death   \n",
       "289957 -0.0086 0.0729  0.9057        20       20000   death   \n",
       "289958  0.0425 0.0719  0.5543        20       20000   death   \n",
       "289959 -0.1480 0.0721  0.0401        20       20000   death   \n",
       "289960 -0.0239 0.0714  0.7382        20       20000   death   \n",
       "289961 -0.0127 0.0745  0.8641        20       20000   death   \n",
       "289962 -0.0921 0.0713  0.1962        20       20000   death   \n",
       "289963  0.0314 0.0721  0.6637        20       20000   death   \n",
       "289964 -0.0348 0.0727  0.6319        20       20000   death   \n",
       "289965 -0.0383 0.0730  0.5998        20       20000   death   \n",
       "289966  0.0038 0.0727  0.9586        20       20000   death   \n",
       "289967 -0.0267 0.0719  0.7105        20       20000   death   \n",
       "289968 -0.0211 0.0719  0.7689        20       20000   death   \n",
       "289969 -0.0222 0.0730  0.7614        20       20000   death   \n",
       "289970  0.1665 0.0732  0.0229        20       20000   death   \n",
       "289971  0.1339 0.0711  0.0596        20       20000   death   \n",
       "289972 -0.0917 0.0728  0.2077        20       20000   death   \n",
       "289973  0.0084 0.0731  0.9090        20       20000   death   \n",
       "289974  0.0814 0.0742  0.2720        20       20000   death   \n",
       "289975  0.1156 0.0745  0.1205        20       20000   death   \n",
       "289976  0.0787 0.0732  0.2824        20       20000   death   \n",
       "289977 -0.0749 0.0747  0.3166        20       20000   death   \n",
       "289978  0.0393 0.0736  0.5934        20       20000   death   \n",
       "289979  0.0466 0.0751  0.5351        20       20000   death   \n",
       "289980  0.0289 0.0735  0.6945        20       20000   death   \n",
       "289981  0.0045 0.0723  0.9499        20       20000   death   \n",
       "289982  0.0994 0.0747  0.1831        20       20000   death   \n",
       "289983 -0.0775 0.0746  0.2988        20       20000   death   \n",
       "289984  0.0667 0.0740  0.3673        20       20000   death   \n",
       "289985  0.0566 0.0739  0.4433        20       20000   death   \n",
       "289986 -0.0374 0.0749  0.6177        20       20000   death   \n",
       "289987 -0.0593 0.0756  0.4324        20       20000   death   \n",
       "289988 -0.0699 0.0738  0.3437        20       20000   death   \n",
       "289989 -0.0330 0.0714  0.6444        20       20000   death   \n",
       "289990  0.0695 0.0730  0.3409        20       20000   death   \n",
       "289991  0.0623 0.0733  0.3954        20       20000   death   \n",
       "289992 -0.0448 0.0697  0.5202        20       20000   death   \n",
       "289993  0.1174 0.0737  0.1112        20       20000   death   \n",
       "289994 -0.0289 0.0748  0.6991        20       20000   death   \n",
       "289995 -0.0184 0.0734  0.8023        20       20000   death   \n",
       "289996  0.0662 0.0723  0.3601        20       20000   death   \n",
       "289997 -0.0118 0.0725  0.8705        20       20000   death   \n",
       "289998 -0.0767 0.0737  0.2981        20       20000   death   \n",
       "289999  0.0256 0.0707  0.7172        20       20000   death   \n",
       "301950 -0.0273 0.1338  0.8383        20       20000   death   \n",
       "301951 -0.1231 0.1427  0.3884        20       20000   death   \n",
       "301952  0.0222 0.1421  0.8758        20       20000   death   \n",
       "301953  0.1672 0.1287  0.1940        20       20000   death   \n",
       "301954  0.0504 0.1286  0.6949        20       20000   death   \n",
       "301955  0.0700 0.1322  0.5963        20       20000   death   \n",
       "301956 -0.0858 0.1328  0.5181        20       20000   death   \n",
       "301957  0.0583 0.1305  0.6548        20       20000   death   \n",
       "301958 -0.1058 0.1337  0.4286        20       20000   death   \n",
       "301959 -0.1368 0.1302  0.2934        20       20000   death   \n",
       "301960 -0.0861 0.1345  0.5221        20       20000   death   \n",
       "301961 -0.0776 0.1330  0.5593        20       20000   death   \n",
       "301962 -0.0030 0.1387  0.9826        20       20000   death   \n",
       "301963 -0.0112 0.1275  0.9302        20       20000   death   \n",
       "301964 -0.2569 0.1281  0.0450        20       20000   death   \n",
       "301965 -0.0457 0.1289  0.7226        20       20000   death   \n",
       "301966  0.0626 0.1305  0.6314        20       20000   death   \n",
       "301967  0.1168 0.1291  0.3658        20       20000   death   \n",
       "301968 -0.0953 0.1328  0.4729        20       20000   death   \n",
       "301969 -0.0179 0.1332  0.8932        20       20000   death   \n",
       "301970  0.0592 0.1395  0.6714        20       20000   death   \n",
       "301971  0.0036 0.1302  0.9779        20       20000   death   \n",
       "301972  0.0330 0.1310  0.8008        20       20000   death   \n",
       "301973 -0.1391 0.1221  0.2545        20       20000   death   \n",
       "301974  0.1702 0.1321  0.1976        20       20000   death   \n",
       "301975  0.1310 0.1323  0.3223        20       20000   death   \n",
       "301976 -0.0630 0.1336  0.6371        20       20000   death   \n",
       "301977  0.0395 0.1321  0.7647        20       20000   death   \n",
       "301978 -0.1369 0.1350  0.3106        20       20000   death   \n",
       "301979  0.2178 0.1293  0.0923        20       20000   death   \n",
       "301980 -0.0450 0.1362  0.7409        20       20000   death   \n",
       "301981  0.1168 0.1352  0.3879        20       20000   death   \n",
       "301982 -0.0184 0.1278  0.8858        20       20000   death   \n",
       "301983 -0.0813 0.1316  0.5370        20       20000   death   \n",
       "301984  0.0136 0.1344  0.9197        20       20000   death   \n",
       "301985  0.0435 0.1324  0.7426        20       20000   death   \n",
       "301986 -0.2828 0.1416  0.0458        20       20000   death   \n",
       "301987 -0.3516 0.1267  0.0055        20       20000   death   \n",
       "301988  0.0781 0.1433  0.5859        20       20000   death   \n",
       "301989 -0.2794 0.1304  0.0321        20       20000   death   \n",
       "301990  0.1597 0.1350  0.2367        20       20000   death   \n",
       "301991 -0.2274 0.1358  0.0940        20       20000   death   \n",
       "301992  0.0371 0.1319  0.7782        20       20000   death   \n",
       "301993  0.0057 0.1350  0.9665        20       20000   death   \n",
       "301994 -0.0665 0.1294  0.6071        20       20000   death   \n",
       "301995  0.1523 0.1226  0.2142        20       20000   death   \n",
       "301996 -0.1193 0.1348  0.3765        20       20000   death   \n",
       "301997 -0.0000 0.1302  0.9998        20       20000   death   \n",
       "301998  0.0402 0.1338  0.7641        20       20000   death   \n",
       "301999 -0.0889 0.1282  0.4883        20       20000   death   \n",
       "\n",
       "                        analysis  dementiaRisk  cvRisk  runMeanReg  \n",
       "289950  logisticRegression-death        0.0013  0.0026     -0.0404  \n",
       "289951  logisticRegression-death        0.0013  0.0026     -0.0051  \n",
       "289952  logisticRegression-death        0.0013  0.0026     -0.0268  \n",
       "289953  logisticRegression-death        0.0013  0.0026     -0.0017  \n",
       "289954  logisticRegression-death        0.0013  0.0026      0.0153  \n",
       "289955  logisticRegression-death        0.0013  0.0026      0.0085  \n",
       "289956  logisticRegression-death        0.0013  0.0026      0.0017  \n",
       "289957  logisticRegression-death        0.0013  0.0026      0.0004  \n",
       "289958  logisticRegression-death        0.0013  0.0026      0.0051  \n",
       "289959  logisticRegression-death        0.0013  0.0026     -0.0102  \n",
       "289960  logisticRegression-death        0.0013  0.0026     -0.0115  \n",
       "289961  logisticRegression-death        0.0013  0.0026     -0.0116  \n",
       "289962  logisticRegression-death        0.0013  0.0026     -0.0178  \n",
       "289963  logisticRegression-death        0.0013  0.0026     -0.0143  \n",
       "289964  logisticRegression-death        0.0013  0.0026     -0.0156  \n",
       "289965  logisticRegression-death        0.0013  0.0026     -0.0170  \n",
       "289966  logisticRegression-death        0.0013  0.0026     -0.0158  \n",
       "289967  logisticRegression-death        0.0013  0.0026     -0.0164  \n",
       "289968  logisticRegression-death        0.0013  0.0026     -0.0167  \n",
       "289969  logisticRegression-death        0.0013  0.0026     -0.0169  \n",
       "289970  logisticRegression-death        0.0013  0.0026     -0.0082  \n",
       "289971  logisticRegression-death        0.0013  0.0026     -0.0017  \n",
       "289972  logisticRegression-death        0.0013  0.0026     -0.0057  \n",
       "289973  logisticRegression-death        0.0013  0.0026     -0.0051  \n",
       "289974  logisticRegression-death        0.0013  0.0026     -0.0016  \n",
       "289975  logisticRegression-death        0.0013  0.0026      0.0029  \n",
       "289976  logisticRegression-death        0.0013  0.0026      0.0057  \n",
       "289977  logisticRegression-death        0.0013  0.0026      0.0028  \n",
       "289978  logisticRegression-death        0.0013  0.0026      0.0041  \n",
       "289979  logisticRegression-death        0.0013  0.0026      0.0055  \n",
       "289980  logisticRegression-death        0.0013  0.0026      0.0063  \n",
       "289981  logisticRegression-death        0.0013  0.0026      0.0062  \n",
       "289982  logisticRegression-death        0.0013  0.0026      0.0090  \n",
       "289983  logisticRegression-death        0.0013  0.0026      0.0065  \n",
       "289984  logisticRegression-death        0.0013  0.0026      0.0082  \n",
       "289985  logisticRegression-death        0.0013  0.0026      0.0095  \n",
       "289986  logisticRegression-death        0.0013  0.0026      0.0083  \n",
       "289987  logisticRegression-death        0.0013  0.0026      0.0065  \n",
       "289988  logisticRegression-death        0.0013  0.0026      0.0045  \n",
       "289989  logisticRegression-death        0.0013  0.0026      0.0036  \n",
       "289990  logisticRegression-death        0.0013  0.0026      0.0052  \n",
       "289991  logisticRegression-death        0.0013  0.0026      0.0066  \n",
       "289992  logisticRegression-death        0.0013  0.0026      0.0054  \n",
       "289993  logisticRegression-death        0.0013  0.0026      0.0079  \n",
       "289994  logisticRegression-death        0.0013  0.0026      0.0071  \n",
       "289995  logisticRegression-death        0.0013  0.0026      0.0065  \n",
       "289996  logisticRegression-death        0.0013  0.0026      0.0078  \n",
       "289997  logisticRegression-death        0.0013  0.0026      0.0074  \n",
       "289998  logisticRegression-death        0.0013  0.0026      0.0057  \n",
       "289999  logisticRegression-death        0.0013  0.0026      0.0061  \n",
       "301950  logisticRegression-death        0.0013  0.0026      0.0054  \n",
       "301951  logisticRegression-death        0.0013  0.0026      0.0030  \n",
       "301952  logisticRegression-death        0.0013  0.0026      0.0033  \n",
       "301953  logisticRegression-death        0.0013  0.0026      0.0064  \n",
       "301954  logisticRegression-death        0.0013  0.0026      0.0072  \n",
       "301955  logisticRegression-death        0.0013  0.0026      0.0083  \n",
       "301956  logisticRegression-death        0.0013  0.0026      0.0066  \n",
       "301957  logisticRegression-death        0.0013  0.0026      0.0075  \n",
       "301958  logisticRegression-death        0.0013  0.0026      0.0056  \n",
       "301959  logisticRegression-death        0.0013  0.0026      0.0032  \n",
       "301960  logisticRegression-death        0.0013  0.0026      0.0018  \n",
       "301961  logisticRegression-death        0.0013  0.0026      0.0005  \n",
       "301962  logisticRegression-death        0.0013  0.0026      0.0004  \n",
       "301963  logisticRegression-death        0.0013  0.0026      0.0002  \n",
       "301964  logisticRegression-death        0.0013  0.0026     -0.0037  \n",
       "301965  logisticRegression-death        0.0013  0.0026     -0.0043  \n",
       "301966  logisticRegression-death        0.0013  0.0026     -0.0033  \n",
       "301967  logisticRegression-death        0.0013  0.0026     -0.0016  \n",
       "301968  logisticRegression-death        0.0013  0.0026     -0.0029  \n",
       "301969  logisticRegression-death        0.0013  0.0026     -0.0032  \n",
       "301970  logisticRegression-death        0.0013  0.0026     -0.0023  \n",
       "301971  logisticRegression-death        0.0013  0.0026     -0.0022  \n",
       "301972  logisticRegression-death        0.0013  0.0026     -0.0017  \n",
       "301973  logisticRegression-death        0.0013  0.0026     -0.0036  \n",
       "301974  logisticRegression-death        0.0013  0.0026     -0.0012  \n",
       "301975  logisticRegression-death        0.0013  0.0026      0.0005  \n",
       "301976  logisticRegression-death        0.0013  0.0026     -0.0003  \n",
       "301977  logisticRegression-death        0.0013  0.0026      0.0002  \n",
       "301978  logisticRegression-death        0.0013  0.0026     -0.0016  \n",
       "301979  logisticRegression-death        0.0013  0.0026      0.0012  \n",
       "301980  logisticRegression-death        0.0013  0.0026      0.0006  \n",
       "301981  logisticRegression-death        0.0013  0.0026      0.0020  \n",
       "301982  logisticRegression-death        0.0013  0.0026      0.0018  \n",
       "301983  logisticRegression-death        0.0013  0.0026      0.0008  \n",
       "301984  logisticRegression-death        0.0013  0.0026      0.0009  \n",
       "301985  logisticRegression-death        0.0013  0.0026      0.0014  \n",
       "301986  logisticRegression-death        0.0013  0.0026     -0.0018  \n",
       "301987  logisticRegression-death        0.0013  0.0026     -0.0058  \n",
       "301988  logisticRegression-death        0.0013  0.0026     -0.0049  \n",
       "301989  logisticRegression-death        0.0013  0.0026     -0.0079  \n",
       "301990  logisticRegression-death        0.0013  0.0026     -0.0061  \n",
       "301991  logisticRegression-death        0.0013  0.0026     -0.0085  \n",
       "301992  logisticRegression-death        0.0013  0.0026     -0.0080  \n",
       "301993  logisticRegression-death        0.0013  0.0026     -0.0078  \n",
       "301994  logisticRegression-death        0.0013  0.0026     -0.0085  \n",
       "301995  logisticRegression-death        0.0013  0.0026     -0.0068  \n",
       "301996  logisticRegression-death        0.0013  0.0026     -0.0079  \n",
       "301997  logisticRegression-death        0.0013  0.0026     -0.0079  \n",
       "301998  logisticRegression-death        0.0013  0.0026     -0.0074  \n",
       "301999  logisticRegression-death        0.0013  0.0026     -0.0082  "
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results.loc[ (results[\"outcome\"]==outcomes[0]) & \n",
    "                    (results[\"sampleSize\"]==sampleSizes[7]) &\n",
    "                    (results[\"dementiaRisk\"]==dementiaRisks[2]) & \n",
    "                    (results[\"cvRisk\"]==cvRisks[2]) &\n",
    "                    (results[\"duration\"]==durations[4]) ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "bbf5de34",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array(['death', 'deathstroke-mi-dementia-', 'deathstroke-mi-',\n",
       "        '_qalys-sum', '_gcp-mean', '_gcp-last'], dtype=object),\n",
       " array([ 3,  5, 10, 15, 20]),\n",
       " array([  100,   200,   500,  1000,  5000, 10000, 15000, 20000]),\n",
       " array([1.16760305e-06, 8.19374349e-04, 2.61911059e-03, 6.09125141e-03,\n",
       "        1.32184646e-02]),\n",
       " array([2.48458399e-08, 1.85764173e-04, 1.29172709e-03, 5.87051016e-03,\n",
       "        2.57394432e-02]))"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#just a reminder of the values, unsure about the source of nan at the end\n",
    "outcomes,durations,sampleSizes,cvRisks,dementiaRisks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "4108ecd4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20000\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#note: any plots that include less than 100 data points is due to regression returning nan \n",
    "#note: I have not implemented anything yet on dealing with nan, eg resubmitting the calculation\n",
    "#note: the single dot at the end is just for validation of my running average\n",
    "\n",
    "#for outcome in outcomes: #plot for all outcomes\n",
    "for outcome in [outcomes[0]]:   #set a specific outcome\n",
    "    #for duration in durations: #plot for all durations\n",
    "    for duration in [durations[4]]: \n",
    "        #for sampleSize in sampleSizes: #plot for all sample sizes\n",
    "        for sampleSize in [sampleSizes[7]]:\n",
    "            print(sampleSize)\n",
    "            #for iCvRisk in range(len(cvRisks)): #plot for all cv risks\n",
    "            for iCvRisk in [2]: #set a specific risk, 0-4            \n",
    "                #for iDementiaRisk in range(len(dementiaRisks)): #plot for all dementia risks\n",
    "                for iDementiaRisk in [2]: #set a specific dementia risk, 0-4\n",
    "                    plotData=results.loc[ #get all relevant data\n",
    "                    (results[\"outcome\"]==outcome) & \n",
    "                    (results[\"sampleSize\"]==sampleSize) &\n",
    "                    (results[\"dementiaRisk\"]==dementiaRisks[iDementiaRisk]) & \n",
    "                    (results[\"cvRisk\"]==cvRisks[iCvRisk]) &\n",
    "                    (results[\"duration\"]==duration), \"runMeanReg\"].copy()\n",
    "                    plt.scatter(range(len(plotData)),plotData)\n",
    "                    plt.scatter(99,meanReg[f\"{outcome},{duration},{sampleSize}\"][iCvRisk,iDementiaRisk])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9578b30",
   "metadata": {},
   "outputs": [],
   "source": [
    "for outcome in [outcomes[0]]:    #change to outcomes in order to see all heatmaps associated with all outcomes\n",
    "    for duration in durations:\n",
    "        for sampleSize in [sampleSizes[0]]:  #change to sampleSizes to see heatmaps associated with all sample sizes\n",
    "            print(f\"{outcomes[0]},{durations[0]},{sampleSizes[0]}\")\n",
    "            dataForPlot=meanReg[f\"{outcomes[0]},{durations[0]},{sampleSizes[0]}\"]\n",
    "            fig, ax = plt.subplots()\n",
    "            im = ax.imshow(dataForPlot)\n",
    "\n",
    "            # Show all ticks and label them with the respective list entries\n",
    "            ax.set_xticks(np.arange(len(cvRisks)), labels=cvRisks)\n",
    "            ax.set_yticks(np.arange(len(dementiaRisks)), labels=dementiaRisks)\n",
    "            ax.set(xlabel='cv risk', ylabel='dementia risk')\n",
    "\n",
    "            # Rotate the tick labels and set their alignment.\n",
    "            plt.setp(ax.get_xticklabels(), rotation=45, ha=\"right\",\n",
    "            rotation_mode=\"anchor\")\n",
    "\n",
    "            cbar = ax.figure.colorbar(im, ax=ax)\n",
    "            cbar.ax.set_ylabel(\"mean effect size\", rotation=-90, va=\"bottom\")\n",
    "\n",
    "            ax.set_title(\"mean effect size\")\n",
    "            fig.tight_layout()\n",
    "            plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9de6dc95",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "microsimKernel",
   "language": "python",
   "name": "microsimkernel"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
