{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b2c851d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#needs a kernel that can load matplotlib, pandas, numpy (does not need to be a microsim kernel)\n",
    "#if you run this on OSC and the kernel dies as you run it, run the notebook with more than 1 cores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4ed6159b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "pd.set_option('display.max_columns', None)\n",
    "pd.set_option('max_colwidth', None)\n",
    "#pd.set_option('max_rows', None)\n",
    "#pd.set_option('max_columns', None)\n",
    "pd.set_option('display.max_rows', None)\n",
    "pd.options.display.float_format = '{:,.4f}'.format\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ee97e248",
   "metadata": {},
   "outputs": [],
   "source": [
    "#resultsDir = \"/users/PAS2164/deligkaris/MICROSIM/SIMULATIONS/PRELIMINARY-TRIALS-100-CV-ALL-DEMENTIA-ALL\"\n",
    "resultsDir = \"/Users/deligkaris.1/OneDrive - The Ohio State University Wexner Medical Center/MICROSIM/SIMULATIONS/PRELIMINARY-TRIALS-100-CV-ALL-DEMENTIA-ALL\"\n",
    "os.chdir(resultsDir)\n",
    "data=pd.read_csv(\"inputLog.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "37486efe",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>reg</th>\n",
       "      <th>se</th>\n",
       "      <th>pvalue</th>\n",
       "      <th>duration</th>\n",
       "      <th>sampleSize</th>\n",
       "      <th>outcome</th>\n",
       "      <th>analysis</th>\n",
       "      <th>dementiaRisk</th>\n",
       "      <th>cvRisk</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-28.6097</td>\n",
       "      <td>1,130,140.1029</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>3</td>\n",
       "      <td>100</td>\n",
       "      <td>death</td>\n",
       "      <td>logisticRegression-death</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3</td>\n",
       "      <td>100</td>\n",
       "      <td>death</td>\n",
       "      <td>logisticRegression-death</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3</td>\n",
       "      <td>100</td>\n",
       "      <td>death</td>\n",
       "      <td>logisticRegression-death</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3</td>\n",
       "      <td>100</td>\n",
       "      <td>death</td>\n",
       "      <td>logisticRegression-death</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3</td>\n",
       "      <td>100</td>\n",
       "      <td>death</td>\n",
       "      <td>logisticRegression-death</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       reg             se  pvalue  duration  sampleSize outcome  \\\n",
       "0 -28.6097 1,130,140.1029  1.0000         3         100   death   \n",
       "1      NaN            NaN     NaN         3         100   death   \n",
       "2      NaN            NaN     NaN         3         100   death   \n",
       "3      NaN            NaN     NaN         3         100   death   \n",
       "4      NaN            NaN     NaN         3         100   death   \n",
       "\n",
       "                   analysis  dementiaRisk  cvRisk  \n",
       "0  logisticRegression-death        0.0000  0.0000  \n",
       "1  logisticRegression-death        0.0000  0.0000  \n",
       "2  logisticRegression-death        0.0000  0.0000  \n",
       "3  logisticRegression-death        0.0000  0.0000  \n",
       "4  logisticRegression-death        0.0000  0.0000  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#some regression results are nan\n",
    "data.head() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "87d52544",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(600000, 9)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "2dc78458",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(13764, 0.02294)"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#how many regressions returned nan in absolute number and percent wise \n",
    "data[\"reg\"].isna().sum(),data[\"reg\"].isna().sum()/data.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "d55ee30f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>reg</th>\n",
       "      <th>se</th>\n",
       "      <th>pvalue</th>\n",
       "      <th>duration</th>\n",
       "      <th>sampleSize</th>\n",
       "      <th>outcome</th>\n",
       "      <th>analysis</th>\n",
       "      <th>dementiaRisk</th>\n",
       "      <th>cvRisk</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>84069</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3</td>\n",
       "      <td>200</td>\n",
       "      <td>death</td>\n",
       "      <td>logisticRegression-death</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0061</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36083</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3</td>\n",
       "      <td>200</td>\n",
       "      <td>death</td>\n",
       "      <td>logisticRegression-death</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0008</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>591617</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>20</td>\n",
       "      <td>100</td>\n",
       "      <td>deathstroke-mi-dementia-</td>\n",
       "      <td>logisticRegression-deathstroke-mi-dementia-</td>\n",
       "      <td>0.0257</td>\n",
       "      <td>0.0132</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>197394</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>15</td>\n",
       "      <td>1000</td>\n",
       "      <td>deathstroke-mi-</td>\n",
       "      <td>logisticRegression-deathstroke-mi-</td>\n",
       "      <td>0.0002</td>\n",
       "      <td>0.0061</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>124464</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>5</td>\n",
       "      <td>200</td>\n",
       "      <td>deathstroke-mi-</td>\n",
       "      <td>logisticRegression-deathstroke-mi-</td>\n",
       "      <td>0.0002</td>\n",
       "      <td>0.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>136464</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>5</td>\n",
       "      <td>200</td>\n",
       "      <td>deathstroke-mi-</td>\n",
       "      <td>logisticRegression-deathstroke-mi-</td>\n",
       "      <td>0.0002</td>\n",
       "      <td>0.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>220012</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3</td>\n",
       "      <td>100</td>\n",
       "      <td>deathstroke-mi-</td>\n",
       "      <td>logisticRegression-deathstroke-mi-</td>\n",
       "      <td>0.0002</td>\n",
       "      <td>0.0132</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>63619</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>20</td>\n",
       "      <td>100</td>\n",
       "      <td>deathstroke-mi-dementia-</td>\n",
       "      <td>logisticRegression-deathstroke-mi-dementia-</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0026</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>122082</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3</td>\n",
       "      <td>200</td>\n",
       "      <td>deathstroke-mi-dementia-</td>\n",
       "      <td>logisticRegression-deathstroke-mi-dementia-</td>\n",
       "      <td>0.0002</td>\n",
       "      <td>0.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>471644</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>20</td>\n",
       "      <td>100</td>\n",
       "      <td>deathstroke-mi-dementia-</td>\n",
       "      <td>logisticRegression-deathstroke-mi-dementia-</td>\n",
       "      <td>0.0059</td>\n",
       "      <td>0.0132</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>256400</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>5</td>\n",
       "      <td>100</td>\n",
       "      <td>deathstroke-mi-</td>\n",
       "      <td>logisticRegression-deathstroke-mi-</td>\n",
       "      <td>0.0013</td>\n",
       "      <td>0.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>197320</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>15</td>\n",
       "      <td>500</td>\n",
       "      <td>deathstroke-mi-</td>\n",
       "      <td>logisticRegression-deathstroke-mi-</td>\n",
       "      <td>0.0002</td>\n",
       "      <td>0.0061</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>194995</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>10</td>\n",
       "      <td>1000</td>\n",
       "      <td>deathstroke-mi-dementia-</td>\n",
       "      <td>logisticRegression-deathstroke-mi-dementia-</td>\n",
       "      <td>0.0002</td>\n",
       "      <td>0.0061</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>84001</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3</td>\n",
       "      <td>100</td>\n",
       "      <td>death</td>\n",
       "      <td>logisticRegression-death</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0061</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>122557</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>5</td>\n",
       "      <td>1000</td>\n",
       "      <td>deathstroke-mi-dementia-</td>\n",
       "      <td>logisticRegression-deathstroke-mi-dementia-</td>\n",
       "      <td>0.0002</td>\n",
       "      <td>0.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>194951</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>10</td>\n",
       "      <td>1000</td>\n",
       "      <td>deathstroke-mi-dementia-</td>\n",
       "      <td>logisticRegression-deathstroke-mi-dementia-</td>\n",
       "      <td>0.0002</td>\n",
       "      <td>0.0061</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>136053</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3</td>\n",
       "      <td>200</td>\n",
       "      <td>deathstroke-mi-</td>\n",
       "      <td>logisticRegression-deathstroke-mi-</td>\n",
       "      <td>0.0002</td>\n",
       "      <td>0.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>360499</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>5</td>\n",
       "      <td>200</td>\n",
       "      <td>death</td>\n",
       "      <td>logisticRegression-death</td>\n",
       "      <td>0.0059</td>\n",
       "      <td>0.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>362040</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3</td>\n",
       "      <td>100</td>\n",
       "      <td>deathstroke-mi-dementia-</td>\n",
       "      <td>logisticRegression-deathstroke-mi-dementia-</td>\n",
       "      <td>0.0059</td>\n",
       "      <td>0.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>194138</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3</td>\n",
       "      <td>500</td>\n",
       "      <td>deathstroke-mi-dementia-</td>\n",
       "      <td>logisticRegression-deathstroke-mi-dementia-</td>\n",
       "      <td>0.0002</td>\n",
       "      <td>0.0061</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        reg  se  pvalue  duration  sampleSize                   outcome  \\\n",
       "84069   NaN NaN     NaN         3         200                     death   \n",
       "36083   NaN NaN     NaN         3         200                     death   \n",
       "591617  NaN NaN     NaN        20         100  deathstroke-mi-dementia-   \n",
       "197394  NaN NaN     NaN        15        1000           deathstroke-mi-   \n",
       "124464  NaN NaN     NaN         5         200           deathstroke-mi-   \n",
       "136464  NaN NaN     NaN         5         200           deathstroke-mi-   \n",
       "220012  NaN NaN     NaN         3         100           deathstroke-mi-   \n",
       "63619   NaN NaN     NaN        20         100  deathstroke-mi-dementia-   \n",
       "122082  NaN NaN     NaN         3         200  deathstroke-mi-dementia-   \n",
       "471644  NaN NaN     NaN        20         100  deathstroke-mi-dementia-   \n",
       "256400  NaN NaN     NaN         5         100           deathstroke-mi-   \n",
       "197320  NaN NaN     NaN        15         500           deathstroke-mi-   \n",
       "194995  NaN NaN     NaN        10        1000  deathstroke-mi-dementia-   \n",
       "84001   NaN NaN     NaN         3         100                     death   \n",
       "122557  NaN NaN     NaN         5        1000  deathstroke-mi-dementia-   \n",
       "194951  NaN NaN     NaN        10        1000  deathstroke-mi-dementia-   \n",
       "136053  NaN NaN     NaN         3         200           deathstroke-mi-   \n",
       "360499  NaN NaN     NaN         5         200                     death   \n",
       "362040  NaN NaN     NaN         3         100  deathstroke-mi-dementia-   \n",
       "194138  NaN NaN     NaN         3         500  deathstroke-mi-dementia-   \n",
       "\n",
       "                                           analysis  dementiaRisk  cvRisk  \n",
       "84069                      logisticRegression-death        0.0000  0.0061  \n",
       "36083                      logisticRegression-death        0.0000  0.0008  \n",
       "591617  logisticRegression-deathstroke-mi-dementia-        0.0257  0.0132  \n",
       "197394           logisticRegression-deathstroke-mi-        0.0002  0.0061  \n",
       "124464           logisticRegression-deathstroke-mi-        0.0002  0.0000  \n",
       "136464           logisticRegression-deathstroke-mi-        0.0002  0.0000  \n",
       "220012           logisticRegression-deathstroke-mi-        0.0002  0.0132  \n",
       "63619   logisticRegression-deathstroke-mi-dementia-        0.0000  0.0026  \n",
       "122082  logisticRegression-deathstroke-mi-dementia-        0.0002  0.0000  \n",
       "471644  logisticRegression-deathstroke-mi-dementia-        0.0059  0.0132  \n",
       "256400           logisticRegression-deathstroke-mi-        0.0013  0.0000  \n",
       "197320           logisticRegression-deathstroke-mi-        0.0002  0.0061  \n",
       "194995  logisticRegression-deathstroke-mi-dementia-        0.0002  0.0061  \n",
       "84001                      logisticRegression-death        0.0000  0.0061  \n",
       "122557  logisticRegression-deathstroke-mi-dementia-        0.0002  0.0000  \n",
       "194951  logisticRegression-deathstroke-mi-dementia-        0.0002  0.0061  \n",
       "136053           logisticRegression-deathstroke-mi-        0.0002  0.0000  \n",
       "360499                     logisticRegression-death        0.0059  0.0000  \n",
       "362040  logisticRegression-deathstroke-mi-dementia-        0.0059  0.0000  \n",
       "194138  logisticRegression-deathstroke-mi-dementia-        0.0002  0.0061  "
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# nans tend to be small sample sizes (but not always), results from logistic regression \n",
    "data[data[\"reg\"].isna()].sample(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "6e70097a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "100      5354\n",
       "200      3292\n",
       "500      1623\n",
       "1000     1051\n",
       "5000      630\n",
       "10000     614\n",
       "15000     602\n",
       "20000     598\n",
       "Name: sampleSize, dtype: int64"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#if the result is nan, most likely it is a small sample size\n",
    "#but from one 20,000 sample trial I get 200 100 sample trials and 5354/598 is a factor of ~10 so smaller \n",
    "#sample trials less likely (by a factor of ~20) to return nan in regression\n",
    "data[data[\"reg\"].isna()][\"sampleSize\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f52d2b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "data[data[\"reg\"].isna()][\"outcome\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1dd71138",
   "metadata": {},
   "outputs": [],
   "source": [
    "#linear regression did not result in nan\n",
    "data[data[\"reg\"].isna()][\"analysis\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "697c6b4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "data[data[\"reg\"].isna()][\"dementiaRisk\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a276809",
   "metadata": {},
   "outputs": [],
   "source": [
    "data[data[\"reg\"].isna()][\"cvRisk\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d8681c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "#if count() is doing what I think is doing, then small and large cv risks are more likely to return nan \n",
    "#in logistic regression\n",
    "#note the massive 4015 for dementia risk 0.0002 and 0.0061\n",
    "\n",
    "data[data[\"reg\"].isna()].groupby([\"dementiaRisk\",\"cvRisk\"]).count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "383732e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "#from now on keep rows without nan\n",
    "results = data.dropna(axis=0).copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "908b39f4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>reg</th>\n",
       "      <th>se</th>\n",
       "      <th>pvalue</th>\n",
       "      <th>duration</th>\n",
       "      <th>sampleSize</th>\n",
       "      <th>outcome</th>\n",
       "      <th>analysis</th>\n",
       "      <th>dementiaRisk</th>\n",
       "      <th>cvRisk</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>433769</th>\n",
       "      <td>-0.0473</td>\n",
       "      <td>0.1776</td>\n",
       "      <td>0.7899</td>\n",
       "      <td>20</td>\n",
       "      <td>1000</td>\n",
       "      <td>death</td>\n",
       "      <td>logisticRegression-death</td>\n",
       "      <td>0.0059</td>\n",
       "      <td>0.0061</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5572</th>\n",
       "      <td>-0.0238</td>\n",
       "      <td>0.0366</td>\n",
       "      <td>0.5151</td>\n",
       "      <td>15</td>\n",
       "      <td>20000</td>\n",
       "      <td>deathstroke-mi-</td>\n",
       "      <td>logisticRegression-deathstroke-mi-</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>202180</th>\n",
       "      <td>0.1500</td>\n",
       "      <td>0.4410</td>\n",
       "      <td>0.7338</td>\n",
       "      <td>3</td>\n",
       "      <td>1000</td>\n",
       "      <td>_gcp-last</td>\n",
       "      <td>linearRegression-_gcp-last</td>\n",
       "      <td>0.0002</td>\n",
       "      <td>0.0061</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>474610</th>\n",
       "      <td>0.0516</td>\n",
       "      <td>0.0354</td>\n",
       "      <td>0.1454</td>\n",
       "      <td>5</td>\n",
       "      <td>5000</td>\n",
       "      <td>_qalys-sum</td>\n",
       "      <td>linearRegression-_qalys-sum</td>\n",
       "      <td>0.0059</td>\n",
       "      <td>0.0132</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>140161</th>\n",
       "      <td>-0.0160</td>\n",
       "      <td>0.1508</td>\n",
       "      <td>0.9155</td>\n",
       "      <td>3</td>\n",
       "      <td>1000</td>\n",
       "      <td>_gcp-mean</td>\n",
       "      <td>linearRegression-_gcp-mean</td>\n",
       "      <td>0.0002</td>\n",
       "      <td>0.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>422150</th>\n",
       "      <td>0.4521</td>\n",
       "      <td>0.4320</td>\n",
       "      <td>0.2954</td>\n",
       "      <td>3</td>\n",
       "      <td>1000</td>\n",
       "      <td>deathstroke-mi-dementia-</td>\n",
       "      <td>logisticRegression-deathstroke-mi-dementia-</td>\n",
       "      <td>0.0059</td>\n",
       "      <td>0.0026</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>297591</th>\n",
       "      <td>0.0127</td>\n",
       "      <td>0.0419</td>\n",
       "      <td>0.7608</td>\n",
       "      <td>15</td>\n",
       "      <td>20000</td>\n",
       "      <td>_gcp-mean</td>\n",
       "      <td>linearRegression-_gcp-mean</td>\n",
       "      <td>0.0013</td>\n",
       "      <td>0.0026</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>228463</th>\n",
       "      <td>0.4499</td>\n",
       "      <td>0.4802</td>\n",
       "      <td>0.3488</td>\n",
       "      <td>5</td>\n",
       "      <td>200</td>\n",
       "      <td>death</td>\n",
       "      <td>logisticRegression-death</td>\n",
       "      <td>0.0002</td>\n",
       "      <td>0.0132</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>272301</th>\n",
       "      <td>0.0204</td>\n",
       "      <td>0.0401</td>\n",
       "      <td>0.6108</td>\n",
       "      <td>3</td>\n",
       "      <td>15000</td>\n",
       "      <td>_gcp-mean</td>\n",
       "      <td>linearRegression-_gcp-mean</td>\n",
       "      <td>0.0013</td>\n",
       "      <td>0.0008</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>386277</th>\n",
       "      <td>0.2565</td>\n",
       "      <td>0.2171</td>\n",
       "      <td>0.2375</td>\n",
       "      <td>3</td>\n",
       "      <td>10000</td>\n",
       "      <td>deathstroke-mi-dementia-</td>\n",
       "      <td>logisticRegression-deathstroke-mi-dementia-</td>\n",
       "      <td>0.0059</td>\n",
       "      <td>0.0008</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           reg     se  pvalue  duration  sampleSize                   outcome  \\\n",
       "433769 -0.0473 0.1776  0.7899        20        1000                     death   \n",
       "5572   -0.0238 0.0366  0.5151        15       20000           deathstroke-mi-   \n",
       "202180  0.1500 0.4410  0.7338         3        1000                 _gcp-last   \n",
       "474610  0.0516 0.0354  0.1454         5        5000                _qalys-sum   \n",
       "140161 -0.0160 0.1508  0.9155         3        1000                 _gcp-mean   \n",
       "422150  0.4521 0.4320  0.2954         3        1000  deathstroke-mi-dementia-   \n",
       "297591  0.0127 0.0419  0.7608        15       20000                 _gcp-mean   \n",
       "228463  0.4499 0.4802  0.3488         5         200                     death   \n",
       "272301  0.0204 0.0401  0.6108         3       15000                 _gcp-mean   \n",
       "386277  0.2565 0.2171  0.2375         3       10000  deathstroke-mi-dementia-   \n",
       "\n",
       "                                           analysis  dementiaRisk  cvRisk  \n",
       "433769                     logisticRegression-death        0.0059  0.0061  \n",
       "5572             logisticRegression-deathstroke-mi-        0.0000  0.0000  \n",
       "202180                   linearRegression-_gcp-last        0.0002  0.0061  \n",
       "474610                  linearRegression-_qalys-sum        0.0059  0.0132  \n",
       "140161                   linearRegression-_gcp-mean        0.0002  0.0000  \n",
       "422150  logisticRegression-deathstroke-mi-dementia-        0.0059  0.0026  \n",
       "297591                   linearRegression-_gcp-mean        0.0013  0.0026  \n",
       "228463                     logisticRegression-death        0.0002  0.0132  \n",
       "272301                   linearRegression-_gcp-mean        0.0013  0.0008  \n",
       "386277  logisticRegression-deathstroke-mi-dementia-        0.0059  0.0008  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results.sample(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "8195582e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(586236, 9)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "802543f6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "100    69646\n",
       "Name: sampleSize, dtype: int64"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results.loc[results[\"sampleSize\"]==100][\"sampleSize\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "655e4264",
   "metadata": {},
   "outputs": [],
   "source": [
    "outcomes=results[\"outcome\"].unique()\n",
    "dementiaRisks=results[\"dementiaRisk\"].unique()\n",
    "cvRisks=results[\"cvRisk\"].unique()\n",
    "sampleSizes=results[\"sampleSize\"].unique()\n",
    "durations=results[\"duration\"].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "dbb26be6",
   "metadata": {},
   "outputs": [],
   "source": [
    "meanReg={}  #dictionary, key depends on outcome, duration and sample size, value is an array with cv=row, dem=column\n",
    "meanAbsEffectSize={}\n",
    "results[\"runMeanReg\"]=np.nan #initialize the running mean regression column in the results dataframe\n",
    "results[\"runMeanAbsEffectSize\"]=np.nan\n",
    "runMeanReg = None #initialize temporary pandas series to store the running mean regression\n",
    "runMeanAbsEffectSize = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "3e3cee15",
   "metadata": {},
   "outputs": [],
   "source": [
    "#calculate means and running means for regression\n",
    "#it takes a few minutes (but not unreasonably long)\n",
    "for outcome in outcomes:    \n",
    "    for duration in durations:\n",
    "        for sampleSize in sampleSizes:\n",
    "            #initialize array for specific outcome, duration, sample size\n",
    "            meanReg[f\"{outcome},{duration},{sampleSize}\"]=np.zeros((len(cvRisks),len(dementiaRisks)))\n",
    "            #meanAbsEffectSize[f\"{outcome},{duration},{sampleSize}\"]=np.zeros((len(cvRisks),len(dementiaRisks)))\n",
    "            for iCvRisk in range(len(cvRisks)):\n",
    "                for iDementiaRisk in range(len(dementiaRisks)):\n",
    "                    dfForParameters=results.loc[ #get all relevant data\n",
    "                                    (results[\"outcome\"]==outcome) & \n",
    "                                    (results[\"sampleSize\"]==sampleSize) &\n",
    "                                    (results[\"dementiaRisk\"]==dementiaRisks[iDementiaRisk]) & \n",
    "                                    (results[\"cvRisk\"]==cvRisks[iCvRisk]) &\n",
    "                                    (results[\"duration\"]==duration) ]\n",
    "                    regs=dfForParameters[\"reg\"].copy() #get regression coefficients only\n",
    "                    #absEffectSizes=dfForParameters[\"reg\"].copy()\n",
    "                    meanReg[f\"{outcome},{duration},{sampleSize}\"][iCvRisk,iDementiaRisk]=regs.mean() #store mean\n",
    "                    #calculate and store running mean\n",
    "                    if runMeanReg is None:\n",
    "                        runMeanReg=regs.expanding().mean()\n",
    "                    else:\n",
    "                        runMeanReg=pd.concat([runMeanReg,regs.expanding().mean()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "ea95d25c",
   "metadata": {},
   "outputs": [],
   "source": [
    "results[\"runMeanReg\"]=runMeanReg #store running means in results dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "88c02b63",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>reg</th>\n",
       "      <th>se</th>\n",
       "      <th>pvalue</th>\n",
       "      <th>duration</th>\n",
       "      <th>sampleSize</th>\n",
       "      <th>outcome</th>\n",
       "      <th>analysis</th>\n",
       "      <th>dementiaRisk</th>\n",
       "      <th>cvRisk</th>\n",
       "      <th>runMeanReg</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-28.6097</td>\n",
       "      <td>1,130,140.1029</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>3</td>\n",
       "      <td>100</td>\n",
       "      <td>death</td>\n",
       "      <td>logisticRegression-death</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>-28.6097</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.0000</td>\n",
       "      <td>1.4286</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>3</td>\n",
       "      <td>100</td>\n",
       "      <td>death</td>\n",
       "      <td>logisticRegression-death</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>-14.3048</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>-27.8959</td>\n",
       "      <td>1,130,139.7761</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>3</td>\n",
       "      <td>100</td>\n",
       "      <td>death</td>\n",
       "      <td>logisticRegression-death</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>-18.8352</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>16.9112</td>\n",
       "      <td>4,654.0557</td>\n",
       "      <td>0.9971</td>\n",
       "      <td>3</td>\n",
       "      <td>100</td>\n",
       "      <td>death</td>\n",
       "      <td>logisticRegression-death</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>-9.8986</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0.4265</td>\n",
       "      <td>0.9357</td>\n",
       "      <td>0.6485</td>\n",
       "      <td>3</td>\n",
       "      <td>100</td>\n",
       "      <td>death</td>\n",
       "      <td>logisticRegression-death</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>-7.8336</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       reg             se  pvalue  duration  sampleSize outcome  \\\n",
       "0 -28.6097 1,130,140.1029  1.0000         3         100   death   \n",
       "5   0.0000         1.4286  1.0000         3         100   death   \n",
       "6 -27.8959 1,130,139.7761  1.0000         3         100   death   \n",
       "7  16.9112     4,654.0557  0.9971         3         100   death   \n",
       "9   0.4265         0.9357  0.6485         3         100   death   \n",
       "\n",
       "                   analysis  dementiaRisk  cvRisk  runMeanReg  \n",
       "0  logisticRegression-death        0.0000  0.0000    -28.6097  \n",
       "5  logisticRegression-death        0.0000  0.0000    -14.3048  \n",
       "6  logisticRegression-death        0.0000  0.0000    -18.8352  \n",
       "7  logisticRegression-death        0.0000  0.0000     -9.8986  \n",
       "9  logisticRegression-death        0.0000  0.0000     -7.8336  "
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "471750f5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>reg</th>\n",
       "      <th>se</th>\n",
       "      <th>pvalue</th>\n",
       "      <th>duration</th>\n",
       "      <th>sampleSize</th>\n",
       "      <th>outcome</th>\n",
       "      <th>analysis</th>\n",
       "      <th>dementiaRisk</th>\n",
       "      <th>cvRisk</th>\n",
       "      <th>runMeanReg</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>288350</th>\n",
       "      <td>0.0071</td>\n",
       "      <td>0.0419</td>\n",
       "      <td>0.8651</td>\n",
       "      <td>3</td>\n",
       "      <td>20000</td>\n",
       "      <td>death</td>\n",
       "      <td>logisticRegression-death</td>\n",
       "      <td>0.0013</td>\n",
       "      <td>0.0026</td>\n",
       "      <td>0.0071</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>288351</th>\n",
       "      <td>0.0336</td>\n",
       "      <td>0.0412</td>\n",
       "      <td>0.4144</td>\n",
       "      <td>3</td>\n",
       "      <td>20000</td>\n",
       "      <td>death</td>\n",
       "      <td>logisticRegression-death</td>\n",
       "      <td>0.0013</td>\n",
       "      <td>0.0026</td>\n",
       "      <td>0.0204</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>288352</th>\n",
       "      <td>0.0162</td>\n",
       "      <td>0.0418</td>\n",
       "      <td>0.6992</td>\n",
       "      <td>3</td>\n",
       "      <td>20000</td>\n",
       "      <td>death</td>\n",
       "      <td>logisticRegression-death</td>\n",
       "      <td>0.0013</td>\n",
       "      <td>0.0026</td>\n",
       "      <td>0.0190</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>288353</th>\n",
       "      <td>-0.0166</td>\n",
       "      <td>0.0420</td>\n",
       "      <td>0.6919</td>\n",
       "      <td>3</td>\n",
       "      <td>20000</td>\n",
       "      <td>death</td>\n",
       "      <td>logisticRegression-death</td>\n",
       "      <td>0.0013</td>\n",
       "      <td>0.0026</td>\n",
       "      <td>0.0101</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>288354</th>\n",
       "      <td>0.0006</td>\n",
       "      <td>0.0418</td>\n",
       "      <td>0.9895</td>\n",
       "      <td>3</td>\n",
       "      <td>20000</td>\n",
       "      <td>death</td>\n",
       "      <td>logisticRegression-death</td>\n",
       "      <td>0.0013</td>\n",
       "      <td>0.0026</td>\n",
       "      <td>0.0082</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>288355</th>\n",
       "      <td>-0.0100</td>\n",
       "      <td>0.0417</td>\n",
       "      <td>0.8101</td>\n",
       "      <td>3</td>\n",
       "      <td>20000</td>\n",
       "      <td>death</td>\n",
       "      <td>logisticRegression-death</td>\n",
       "      <td>0.0013</td>\n",
       "      <td>0.0026</td>\n",
       "      <td>0.0051</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>288356</th>\n",
       "      <td>-0.0221</td>\n",
       "      <td>0.0420</td>\n",
       "      <td>0.5980</td>\n",
       "      <td>3</td>\n",
       "      <td>20000</td>\n",
       "      <td>death</td>\n",
       "      <td>logisticRegression-death</td>\n",
       "      <td>0.0013</td>\n",
       "      <td>0.0026</td>\n",
       "      <td>0.0012</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>288357</th>\n",
       "      <td>-0.0051</td>\n",
       "      <td>0.0414</td>\n",
       "      <td>0.9027</td>\n",
       "      <td>3</td>\n",
       "      <td>20000</td>\n",
       "      <td>death</td>\n",
       "      <td>logisticRegression-death</td>\n",
       "      <td>0.0013</td>\n",
       "      <td>0.0026</td>\n",
       "      <td>0.0005</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>288358</th>\n",
       "      <td>0.0099</td>\n",
       "      <td>0.0417</td>\n",
       "      <td>0.8129</td>\n",
       "      <td>3</td>\n",
       "      <td>20000</td>\n",
       "      <td>death</td>\n",
       "      <td>logisticRegression-death</td>\n",
       "      <td>0.0013</td>\n",
       "      <td>0.0026</td>\n",
       "      <td>0.0015</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>288359</th>\n",
       "      <td>-0.0002</td>\n",
       "      <td>0.0419</td>\n",
       "      <td>0.9969</td>\n",
       "      <td>3</td>\n",
       "      <td>20000</td>\n",
       "      <td>death</td>\n",
       "      <td>logisticRegression-death</td>\n",
       "      <td>0.0013</td>\n",
       "      <td>0.0026</td>\n",
       "      <td>0.0013</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>288360</th>\n",
       "      <td>0.0092</td>\n",
       "      <td>0.0414</td>\n",
       "      <td>0.8241</td>\n",
       "      <td>3</td>\n",
       "      <td>20000</td>\n",
       "      <td>death</td>\n",
       "      <td>logisticRegression-death</td>\n",
       "      <td>0.0013</td>\n",
       "      <td>0.0026</td>\n",
       "      <td>0.0020</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>288361</th>\n",
       "      <td>0.0120</td>\n",
       "      <td>0.0411</td>\n",
       "      <td>0.7710</td>\n",
       "      <td>3</td>\n",
       "      <td>20000</td>\n",
       "      <td>death</td>\n",
       "      <td>logisticRegression-death</td>\n",
       "      <td>0.0013</td>\n",
       "      <td>0.0026</td>\n",
       "      <td>0.0029</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>288362</th>\n",
       "      <td>0.0150</td>\n",
       "      <td>0.0417</td>\n",
       "      <td>0.7191</td>\n",
       "      <td>3</td>\n",
       "      <td>20000</td>\n",
       "      <td>death</td>\n",
       "      <td>logisticRegression-death</td>\n",
       "      <td>0.0013</td>\n",
       "      <td>0.0026</td>\n",
       "      <td>0.0038</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>288363</th>\n",
       "      <td>-0.0419</td>\n",
       "      <td>0.0419</td>\n",
       "      <td>0.3179</td>\n",
       "      <td>3</td>\n",
       "      <td>20000</td>\n",
       "      <td>death</td>\n",
       "      <td>logisticRegression-death</td>\n",
       "      <td>0.0013</td>\n",
       "      <td>0.0026</td>\n",
       "      <td>0.0005</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>288364</th>\n",
       "      <td>0.0113</td>\n",
       "      <td>0.0419</td>\n",
       "      <td>0.7866</td>\n",
       "      <td>3</td>\n",
       "      <td>20000</td>\n",
       "      <td>death</td>\n",
       "      <td>logisticRegression-death</td>\n",
       "      <td>0.0013</td>\n",
       "      <td>0.0026</td>\n",
       "      <td>0.0013</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>288365</th>\n",
       "      <td>-0.0439</td>\n",
       "      <td>0.0423</td>\n",
       "      <td>0.2993</td>\n",
       "      <td>3</td>\n",
       "      <td>20000</td>\n",
       "      <td>death</td>\n",
       "      <td>logisticRegression-death</td>\n",
       "      <td>0.0013</td>\n",
       "      <td>0.0026</td>\n",
       "      <td>-0.0016</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>288366</th>\n",
       "      <td>0.0203</td>\n",
       "      <td>0.0418</td>\n",
       "      <td>0.6268</td>\n",
       "      <td>3</td>\n",
       "      <td>20000</td>\n",
       "      <td>death</td>\n",
       "      <td>logisticRegression-death</td>\n",
       "      <td>0.0013</td>\n",
       "      <td>0.0026</td>\n",
       "      <td>-0.0003</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>288367</th>\n",
       "      <td>-0.0026</td>\n",
       "      <td>0.0418</td>\n",
       "      <td>0.9510</td>\n",
       "      <td>3</td>\n",
       "      <td>20000</td>\n",
       "      <td>death</td>\n",
       "      <td>logisticRegression-death</td>\n",
       "      <td>0.0013</td>\n",
       "      <td>0.0026</td>\n",
       "      <td>-0.0004</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>288368</th>\n",
       "      <td>0.0077</td>\n",
       "      <td>0.0418</td>\n",
       "      <td>0.8543</td>\n",
       "      <td>3</td>\n",
       "      <td>20000</td>\n",
       "      <td>death</td>\n",
       "      <td>logisticRegression-death</td>\n",
       "      <td>0.0013</td>\n",
       "      <td>0.0026</td>\n",
       "      <td>0.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>288369</th>\n",
       "      <td>-0.0241</td>\n",
       "      <td>0.0420</td>\n",
       "      <td>0.5671</td>\n",
       "      <td>3</td>\n",
       "      <td>20000</td>\n",
       "      <td>death</td>\n",
       "      <td>logisticRegression-death</td>\n",
       "      <td>0.0013</td>\n",
       "      <td>0.0026</td>\n",
       "      <td>-0.0012</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>288370</th>\n",
       "      <td>0.0566</td>\n",
       "      <td>0.0413</td>\n",
       "      <td>0.1709</td>\n",
       "      <td>3</td>\n",
       "      <td>20000</td>\n",
       "      <td>death</td>\n",
       "      <td>logisticRegression-death</td>\n",
       "      <td>0.0013</td>\n",
       "      <td>0.0026</td>\n",
       "      <td>0.0016</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>288371</th>\n",
       "      <td>0.0061</td>\n",
       "      <td>0.0421</td>\n",
       "      <td>0.8856</td>\n",
       "      <td>3</td>\n",
       "      <td>20000</td>\n",
       "      <td>death</td>\n",
       "      <td>logisticRegression-death</td>\n",
       "      <td>0.0013</td>\n",
       "      <td>0.0026</td>\n",
       "      <td>0.0018</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>288372</th>\n",
       "      <td>-0.0329</td>\n",
       "      <td>0.0425</td>\n",
       "      <td>0.4394</td>\n",
       "      <td>3</td>\n",
       "      <td>20000</td>\n",
       "      <td>death</td>\n",
       "      <td>logisticRegression-death</td>\n",
       "      <td>0.0013</td>\n",
       "      <td>0.0026</td>\n",
       "      <td>0.0003</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>288373</th>\n",
       "      <td>-0.0547</td>\n",
       "      <td>0.0421</td>\n",
       "      <td>0.1939</td>\n",
       "      <td>3</td>\n",
       "      <td>20000</td>\n",
       "      <td>death</td>\n",
       "      <td>logisticRegression-death</td>\n",
       "      <td>0.0013</td>\n",
       "      <td>0.0026</td>\n",
       "      <td>-0.0020</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>288374</th>\n",
       "      <td>0.0509</td>\n",
       "      <td>0.0417</td>\n",
       "      <td>0.2217</td>\n",
       "      <td>3</td>\n",
       "      <td>20000</td>\n",
       "      <td>death</td>\n",
       "      <td>logisticRegression-death</td>\n",
       "      <td>0.0013</td>\n",
       "      <td>0.0026</td>\n",
       "      <td>0.0001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>288375</th>\n",
       "      <td>0.0647</td>\n",
       "      <td>0.0417</td>\n",
       "      <td>0.1211</td>\n",
       "      <td>3</td>\n",
       "      <td>20000</td>\n",
       "      <td>death</td>\n",
       "      <td>logisticRegression-death</td>\n",
       "      <td>0.0013</td>\n",
       "      <td>0.0026</td>\n",
       "      <td>0.0026</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>288376</th>\n",
       "      <td>0.0508</td>\n",
       "      <td>0.0418</td>\n",
       "      <td>0.2242</td>\n",
       "      <td>3</td>\n",
       "      <td>20000</td>\n",
       "      <td>death</td>\n",
       "      <td>logisticRegression-death</td>\n",
       "      <td>0.0013</td>\n",
       "      <td>0.0026</td>\n",
       "      <td>0.0044</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>288377</th>\n",
       "      <td>0.0373</td>\n",
       "      <td>0.0416</td>\n",
       "      <td>0.3700</td>\n",
       "      <td>3</td>\n",
       "      <td>20000</td>\n",
       "      <td>death</td>\n",
       "      <td>logisticRegression-death</td>\n",
       "      <td>0.0013</td>\n",
       "      <td>0.0026</td>\n",
       "      <td>0.0055</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>288378</th>\n",
       "      <td>-0.0505</td>\n",
       "      <td>0.0426</td>\n",
       "      <td>0.2358</td>\n",
       "      <td>3</td>\n",
       "      <td>20000</td>\n",
       "      <td>death</td>\n",
       "      <td>logisticRegression-death</td>\n",
       "      <td>0.0013</td>\n",
       "      <td>0.0026</td>\n",
       "      <td>0.0036</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>288379</th>\n",
       "      <td>0.1120</td>\n",
       "      <td>0.0412</td>\n",
       "      <td>0.0066</td>\n",
       "      <td>3</td>\n",
       "      <td>20000</td>\n",
       "      <td>death</td>\n",
       "      <td>logisticRegression-death</td>\n",
       "      <td>0.0013</td>\n",
       "      <td>0.0026</td>\n",
       "      <td>0.0072</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>288380</th>\n",
       "      <td>0.0315</td>\n",
       "      <td>0.0416</td>\n",
       "      <td>0.4490</td>\n",
       "      <td>3</td>\n",
       "      <td>20000</td>\n",
       "      <td>death</td>\n",
       "      <td>logisticRegression-death</td>\n",
       "      <td>0.0013</td>\n",
       "      <td>0.0026</td>\n",
       "      <td>0.0080</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>288381</th>\n",
       "      <td>0.0486</td>\n",
       "      <td>0.0419</td>\n",
       "      <td>0.2466</td>\n",
       "      <td>3</td>\n",
       "      <td>20000</td>\n",
       "      <td>death</td>\n",
       "      <td>logisticRegression-death</td>\n",
       "      <td>0.0013</td>\n",
       "      <td>0.0026</td>\n",
       "      <td>0.0093</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>288382</th>\n",
       "      <td>0.0068</td>\n",
       "      <td>0.0413</td>\n",
       "      <td>0.8699</td>\n",
       "      <td>3</td>\n",
       "      <td>20000</td>\n",
       "      <td>death</td>\n",
       "      <td>logisticRegression-death</td>\n",
       "      <td>0.0013</td>\n",
       "      <td>0.0026</td>\n",
       "      <td>0.0092</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>288383</th>\n",
       "      <td>-0.0153</td>\n",
       "      <td>0.0419</td>\n",
       "      <td>0.7151</td>\n",
       "      <td>3</td>\n",
       "      <td>20000</td>\n",
       "      <td>death</td>\n",
       "      <td>logisticRegression-death</td>\n",
       "      <td>0.0013</td>\n",
       "      <td>0.0026</td>\n",
       "      <td>0.0085</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>288384</th>\n",
       "      <td>0.0530</td>\n",
       "      <td>0.0418</td>\n",
       "      <td>0.2047</td>\n",
       "      <td>3</td>\n",
       "      <td>20000</td>\n",
       "      <td>death</td>\n",
       "      <td>logisticRegression-death</td>\n",
       "      <td>0.0013</td>\n",
       "      <td>0.0026</td>\n",
       "      <td>0.0098</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>288385</th>\n",
       "      <td>0.0739</td>\n",
       "      <td>0.0418</td>\n",
       "      <td>0.0769</td>\n",
       "      <td>3</td>\n",
       "      <td>20000</td>\n",
       "      <td>death</td>\n",
       "      <td>logisticRegression-death</td>\n",
       "      <td>0.0013</td>\n",
       "      <td>0.0026</td>\n",
       "      <td>0.0115</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>288386</th>\n",
       "      <td>0.0101</td>\n",
       "      <td>0.0416</td>\n",
       "      <td>0.8087</td>\n",
       "      <td>3</td>\n",
       "      <td>20000</td>\n",
       "      <td>death</td>\n",
       "      <td>logisticRegression-death</td>\n",
       "      <td>0.0013</td>\n",
       "      <td>0.0026</td>\n",
       "      <td>0.0115</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>288387</th>\n",
       "      <td>0.1118</td>\n",
       "      <td>0.0417</td>\n",
       "      <td>0.0073</td>\n",
       "      <td>3</td>\n",
       "      <td>20000</td>\n",
       "      <td>death</td>\n",
       "      <td>logisticRegression-death</td>\n",
       "      <td>0.0013</td>\n",
       "      <td>0.0026</td>\n",
       "      <td>0.0141</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>288388</th>\n",
       "      <td>-0.0167</td>\n",
       "      <td>0.0423</td>\n",
       "      <td>0.6928</td>\n",
       "      <td>3</td>\n",
       "      <td>20000</td>\n",
       "      <td>death</td>\n",
       "      <td>logisticRegression-death</td>\n",
       "      <td>0.0013</td>\n",
       "      <td>0.0026</td>\n",
       "      <td>0.0133</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>288389</th>\n",
       "      <td>-0.0316</td>\n",
       "      <td>0.0416</td>\n",
       "      <td>0.4473</td>\n",
       "      <td>3</td>\n",
       "      <td>20000</td>\n",
       "      <td>death</td>\n",
       "      <td>logisticRegression-death</td>\n",
       "      <td>0.0013</td>\n",
       "      <td>0.0026</td>\n",
       "      <td>0.0122</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>288390</th>\n",
       "      <td>-0.0158</td>\n",
       "      <td>0.0418</td>\n",
       "      <td>0.7049</td>\n",
       "      <td>3</td>\n",
       "      <td>20000</td>\n",
       "      <td>death</td>\n",
       "      <td>logisticRegression-death</td>\n",
       "      <td>0.0013</td>\n",
       "      <td>0.0026</td>\n",
       "      <td>0.0115</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>288391</th>\n",
       "      <td>-0.0176</td>\n",
       "      <td>0.0416</td>\n",
       "      <td>0.6721</td>\n",
       "      <td>3</td>\n",
       "      <td>20000</td>\n",
       "      <td>death</td>\n",
       "      <td>logisticRegression-death</td>\n",
       "      <td>0.0013</td>\n",
       "      <td>0.0026</td>\n",
       "      <td>0.0108</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>288392</th>\n",
       "      <td>0.0111</td>\n",
       "      <td>0.0420</td>\n",
       "      <td>0.7915</td>\n",
       "      <td>3</td>\n",
       "      <td>20000</td>\n",
       "      <td>death</td>\n",
       "      <td>logisticRegression-death</td>\n",
       "      <td>0.0013</td>\n",
       "      <td>0.0026</td>\n",
       "      <td>0.0108</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>288393</th>\n",
       "      <td>0.0190</td>\n",
       "      <td>0.0420</td>\n",
       "      <td>0.6508</td>\n",
       "      <td>3</td>\n",
       "      <td>20000</td>\n",
       "      <td>death</td>\n",
       "      <td>logisticRegression-death</td>\n",
       "      <td>0.0013</td>\n",
       "      <td>0.0026</td>\n",
       "      <td>0.0110</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>288394</th>\n",
       "      <td>-0.0001</td>\n",
       "      <td>0.0414</td>\n",
       "      <td>0.9977</td>\n",
       "      <td>3</td>\n",
       "      <td>20000</td>\n",
       "      <td>death</td>\n",
       "      <td>logisticRegression-death</td>\n",
       "      <td>0.0013</td>\n",
       "      <td>0.0026</td>\n",
       "      <td>0.0108</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>288395</th>\n",
       "      <td>0.0184</td>\n",
       "      <td>0.0412</td>\n",
       "      <td>0.6549</td>\n",
       "      <td>3</td>\n",
       "      <td>20000</td>\n",
       "      <td>death</td>\n",
       "      <td>logisticRegression-death</td>\n",
       "      <td>0.0013</td>\n",
       "      <td>0.0026</td>\n",
       "      <td>0.0110</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>288396</th>\n",
       "      <td>0.0060</td>\n",
       "      <td>0.0417</td>\n",
       "      <td>0.8851</td>\n",
       "      <td>3</td>\n",
       "      <td>20000</td>\n",
       "      <td>death</td>\n",
       "      <td>logisticRegression-death</td>\n",
       "      <td>0.0013</td>\n",
       "      <td>0.0026</td>\n",
       "      <td>0.0108</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>288397</th>\n",
       "      <td>-0.0181</td>\n",
       "      <td>0.0414</td>\n",
       "      <td>0.6616</td>\n",
       "      <td>3</td>\n",
       "      <td>20000</td>\n",
       "      <td>death</td>\n",
       "      <td>logisticRegression-death</td>\n",
       "      <td>0.0013</td>\n",
       "      <td>0.0026</td>\n",
       "      <td>0.0102</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>288398</th>\n",
       "      <td>-0.0311</td>\n",
       "      <td>0.0415</td>\n",
       "      <td>0.4533</td>\n",
       "      <td>3</td>\n",
       "      <td>20000</td>\n",
       "      <td>death</td>\n",
       "      <td>logisticRegression-death</td>\n",
       "      <td>0.0013</td>\n",
       "      <td>0.0026</td>\n",
       "      <td>0.0094</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>288399</th>\n",
       "      <td>-0.0162</td>\n",
       "      <td>0.0420</td>\n",
       "      <td>0.6998</td>\n",
       "      <td>3</td>\n",
       "      <td>20000</td>\n",
       "      <td>death</td>\n",
       "      <td>logisticRegression-death</td>\n",
       "      <td>0.0013</td>\n",
       "      <td>0.0026</td>\n",
       "      <td>0.0089</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>300350</th>\n",
       "      <td>0.0499</td>\n",
       "      <td>0.0383</td>\n",
       "      <td>0.1932</td>\n",
       "      <td>3</td>\n",
       "      <td>20000</td>\n",
       "      <td>death</td>\n",
       "      <td>logisticRegression-death</td>\n",
       "      <td>0.0013</td>\n",
       "      <td>0.0026</td>\n",
       "      <td>0.0097</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>300351</th>\n",
       "      <td>0.0318</td>\n",
       "      <td>0.0384</td>\n",
       "      <td>0.4077</td>\n",
       "      <td>3</td>\n",
       "      <td>20000</td>\n",
       "      <td>death</td>\n",
       "      <td>logisticRegression-death</td>\n",
       "      <td>0.0013</td>\n",
       "      <td>0.0026</td>\n",
       "      <td>0.0101</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>300352</th>\n",
       "      <td>0.0630</td>\n",
       "      <td>0.0381</td>\n",
       "      <td>0.0984</td>\n",
       "      <td>3</td>\n",
       "      <td>20000</td>\n",
       "      <td>death</td>\n",
       "      <td>logisticRegression-death</td>\n",
       "      <td>0.0013</td>\n",
       "      <td>0.0026</td>\n",
       "      <td>0.0111</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>300353</th>\n",
       "      <td>0.0411</td>\n",
       "      <td>0.0385</td>\n",
       "      <td>0.2855</td>\n",
       "      <td>3</td>\n",
       "      <td>20000</td>\n",
       "      <td>death</td>\n",
       "      <td>logisticRegression-death</td>\n",
       "      <td>0.0013</td>\n",
       "      <td>0.0026</td>\n",
       "      <td>0.0117</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>300354</th>\n",
       "      <td>0.0635</td>\n",
       "      <td>0.0382</td>\n",
       "      <td>0.0961</td>\n",
       "      <td>3</td>\n",
       "      <td>20000</td>\n",
       "      <td>death</td>\n",
       "      <td>logisticRegression-death</td>\n",
       "      <td>0.0013</td>\n",
       "      <td>0.0026</td>\n",
       "      <td>0.0126</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>300355</th>\n",
       "      <td>0.0407</td>\n",
       "      <td>0.0386</td>\n",
       "      <td>0.2914</td>\n",
       "      <td>3</td>\n",
       "      <td>20000</td>\n",
       "      <td>death</td>\n",
       "      <td>logisticRegression-death</td>\n",
       "      <td>0.0013</td>\n",
       "      <td>0.0026</td>\n",
       "      <td>0.0131</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>300356</th>\n",
       "      <td>0.0673</td>\n",
       "      <td>0.0382</td>\n",
       "      <td>0.0779</td>\n",
       "      <td>3</td>\n",
       "      <td>20000</td>\n",
       "      <td>death</td>\n",
       "      <td>logisticRegression-death</td>\n",
       "      <td>0.0013</td>\n",
       "      <td>0.0026</td>\n",
       "      <td>0.0141</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>300357</th>\n",
       "      <td>0.0261</td>\n",
       "      <td>0.0382</td>\n",
       "      <td>0.4949</td>\n",
       "      <td>3</td>\n",
       "      <td>20000</td>\n",
       "      <td>death</td>\n",
       "      <td>logisticRegression-death</td>\n",
       "      <td>0.0013</td>\n",
       "      <td>0.0026</td>\n",
       "      <td>0.0143</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>300358</th>\n",
       "      <td>0.0530</td>\n",
       "      <td>0.0383</td>\n",
       "      <td>0.1659</td>\n",
       "      <td>3</td>\n",
       "      <td>20000</td>\n",
       "      <td>death</td>\n",
       "      <td>logisticRegression-death</td>\n",
       "      <td>0.0013</td>\n",
       "      <td>0.0026</td>\n",
       "      <td>0.0149</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>300359</th>\n",
       "      <td>0.0152</td>\n",
       "      <td>0.0385</td>\n",
       "      <td>0.6922</td>\n",
       "      <td>3</td>\n",
       "      <td>20000</td>\n",
       "      <td>death</td>\n",
       "      <td>logisticRegression-death</td>\n",
       "      <td>0.0013</td>\n",
       "      <td>0.0026</td>\n",
       "      <td>0.0149</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>300360</th>\n",
       "      <td>0.0648</td>\n",
       "      <td>0.0381</td>\n",
       "      <td>0.0895</td>\n",
       "      <td>3</td>\n",
       "      <td>20000</td>\n",
       "      <td>death</td>\n",
       "      <td>logisticRegression-death</td>\n",
       "      <td>0.0013</td>\n",
       "      <td>0.0026</td>\n",
       "      <td>0.0158</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>300361</th>\n",
       "      <td>0.0491</td>\n",
       "      <td>0.0386</td>\n",
       "      <td>0.2033</td>\n",
       "      <td>3</td>\n",
       "      <td>20000</td>\n",
       "      <td>death</td>\n",
       "      <td>logisticRegression-death</td>\n",
       "      <td>0.0013</td>\n",
       "      <td>0.0026</td>\n",
       "      <td>0.0163</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>300362</th>\n",
       "      <td>0.0658</td>\n",
       "      <td>0.0383</td>\n",
       "      <td>0.0855</td>\n",
       "      <td>3</td>\n",
       "      <td>20000</td>\n",
       "      <td>death</td>\n",
       "      <td>logisticRegression-death</td>\n",
       "      <td>0.0013</td>\n",
       "      <td>0.0026</td>\n",
       "      <td>0.0171</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>300363</th>\n",
       "      <td>0.0447</td>\n",
       "      <td>0.0387</td>\n",
       "      <td>0.2478</td>\n",
       "      <td>3</td>\n",
       "      <td>20000</td>\n",
       "      <td>death</td>\n",
       "      <td>logisticRegression-death</td>\n",
       "      <td>0.0013</td>\n",
       "      <td>0.0026</td>\n",
       "      <td>0.0175</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>300364</th>\n",
       "      <td>0.0583</td>\n",
       "      <td>0.0381</td>\n",
       "      <td>0.1262</td>\n",
       "      <td>3</td>\n",
       "      <td>20000</td>\n",
       "      <td>death</td>\n",
       "      <td>logisticRegression-death</td>\n",
       "      <td>0.0013</td>\n",
       "      <td>0.0026</td>\n",
       "      <td>0.0181</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>300365</th>\n",
       "      <td>0.0405</td>\n",
       "      <td>0.0385</td>\n",
       "      <td>0.2930</td>\n",
       "      <td>3</td>\n",
       "      <td>20000</td>\n",
       "      <td>death</td>\n",
       "      <td>logisticRegression-death</td>\n",
       "      <td>0.0013</td>\n",
       "      <td>0.0026</td>\n",
       "      <td>0.0185</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>300366</th>\n",
       "      <td>0.0526</td>\n",
       "      <td>0.0383</td>\n",
       "      <td>0.1693</td>\n",
       "      <td>3</td>\n",
       "      <td>20000</td>\n",
       "      <td>death</td>\n",
       "      <td>logisticRegression-death</td>\n",
       "      <td>0.0013</td>\n",
       "      <td>0.0026</td>\n",
       "      <td>0.0190</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>300367</th>\n",
       "      <td>0.0420</td>\n",
       "      <td>0.0385</td>\n",
       "      <td>0.2748</td>\n",
       "      <td>3</td>\n",
       "      <td>20000</td>\n",
       "      <td>death</td>\n",
       "      <td>logisticRegression-death</td>\n",
       "      <td>0.0013</td>\n",
       "      <td>0.0026</td>\n",
       "      <td>0.0193</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>300368</th>\n",
       "      <td>0.0700</td>\n",
       "      <td>0.0382</td>\n",
       "      <td>0.0666</td>\n",
       "      <td>3</td>\n",
       "      <td>20000</td>\n",
       "      <td>death</td>\n",
       "      <td>logisticRegression-death</td>\n",
       "      <td>0.0013</td>\n",
       "      <td>0.0026</td>\n",
       "      <td>0.0201</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>300369</th>\n",
       "      <td>0.0349</td>\n",
       "      <td>0.0385</td>\n",
       "      <td>0.3650</td>\n",
       "      <td>3</td>\n",
       "      <td>20000</td>\n",
       "      <td>death</td>\n",
       "      <td>logisticRegression-death</td>\n",
       "      <td>0.0013</td>\n",
       "      <td>0.0026</td>\n",
       "      <td>0.0203</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>300370</th>\n",
       "      <td>-0.0025</td>\n",
       "      <td>0.0385</td>\n",
       "      <td>0.9478</td>\n",
       "      <td>3</td>\n",
       "      <td>20000</td>\n",
       "      <td>death</td>\n",
       "      <td>logisticRegression-death</td>\n",
       "      <td>0.0013</td>\n",
       "      <td>0.0026</td>\n",
       "      <td>0.0200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>300371</th>\n",
       "      <td>-0.0025</td>\n",
       "      <td>0.0387</td>\n",
       "      <td>0.9480</td>\n",
       "      <td>3</td>\n",
       "      <td>20000</td>\n",
       "      <td>death</td>\n",
       "      <td>logisticRegression-death</td>\n",
       "      <td>0.0013</td>\n",
       "      <td>0.0026</td>\n",
       "      <td>0.0196</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>300372</th>\n",
       "      <td>0.0283</td>\n",
       "      <td>0.0381</td>\n",
       "      <td>0.4572</td>\n",
       "      <td>3</td>\n",
       "      <td>20000</td>\n",
       "      <td>death</td>\n",
       "      <td>logisticRegression-death</td>\n",
       "      <td>0.0013</td>\n",
       "      <td>0.0026</td>\n",
       "      <td>0.0198</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>300373</th>\n",
       "      <td>0.0516</td>\n",
       "      <td>0.0383</td>\n",
       "      <td>0.1784</td>\n",
       "      <td>3</td>\n",
       "      <td>20000</td>\n",
       "      <td>death</td>\n",
       "      <td>logisticRegression-death</td>\n",
       "      <td>0.0013</td>\n",
       "      <td>0.0026</td>\n",
       "      <td>0.0202</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>300374</th>\n",
       "      <td>-0.0632</td>\n",
       "      <td>0.0384</td>\n",
       "      <td>0.0996</td>\n",
       "      <td>3</td>\n",
       "      <td>20000</td>\n",
       "      <td>death</td>\n",
       "      <td>logisticRegression-death</td>\n",
       "      <td>0.0013</td>\n",
       "      <td>0.0026</td>\n",
       "      <td>0.0191</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>300375</th>\n",
       "      <td>0.0494</td>\n",
       "      <td>0.0382</td>\n",
       "      <td>0.1955</td>\n",
       "      <td>3</td>\n",
       "      <td>20000</td>\n",
       "      <td>death</td>\n",
       "      <td>logisticRegression-death</td>\n",
       "      <td>0.0013</td>\n",
       "      <td>0.0026</td>\n",
       "      <td>0.0195</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>300376</th>\n",
       "      <td>-0.0656</td>\n",
       "      <td>0.0386</td>\n",
       "      <td>0.0893</td>\n",
       "      <td>3</td>\n",
       "      <td>20000</td>\n",
       "      <td>death</td>\n",
       "      <td>logisticRegression-death</td>\n",
       "      <td>0.0013</td>\n",
       "      <td>0.0026</td>\n",
       "      <td>0.0184</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>300377</th>\n",
       "      <td>0.0361</td>\n",
       "      <td>0.0386</td>\n",
       "      <td>0.3487</td>\n",
       "      <td>3</td>\n",
       "      <td>20000</td>\n",
       "      <td>death</td>\n",
       "      <td>logisticRegression-death</td>\n",
       "      <td>0.0013</td>\n",
       "      <td>0.0026</td>\n",
       "      <td>0.0186</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>300378</th>\n",
       "      <td>-0.0618</td>\n",
       "      <td>0.0386</td>\n",
       "      <td>0.1093</td>\n",
       "      <td>3</td>\n",
       "      <td>20000</td>\n",
       "      <td>death</td>\n",
       "      <td>logisticRegression-death</td>\n",
       "      <td>0.0013</td>\n",
       "      <td>0.0026</td>\n",
       "      <td>0.0176</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>300379</th>\n",
       "      <td>0.0134</td>\n",
       "      <td>0.0387</td>\n",
       "      <td>0.7298</td>\n",
       "      <td>3</td>\n",
       "      <td>20000</td>\n",
       "      <td>death</td>\n",
       "      <td>logisticRegression-death</td>\n",
       "      <td>0.0013</td>\n",
       "      <td>0.0026</td>\n",
       "      <td>0.0175</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>300380</th>\n",
       "      <td>-0.0719</td>\n",
       "      <td>0.0384</td>\n",
       "      <td>0.0613</td>\n",
       "      <td>3</td>\n",
       "      <td>20000</td>\n",
       "      <td>death</td>\n",
       "      <td>logisticRegression-death</td>\n",
       "      <td>0.0013</td>\n",
       "      <td>0.0026</td>\n",
       "      <td>0.0164</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>300381</th>\n",
       "      <td>0.0275</td>\n",
       "      <td>0.0381</td>\n",
       "      <td>0.4713</td>\n",
       "      <td>3</td>\n",
       "      <td>20000</td>\n",
       "      <td>death</td>\n",
       "      <td>logisticRegression-death</td>\n",
       "      <td>0.0013</td>\n",
       "      <td>0.0026</td>\n",
       "      <td>0.0166</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>300382</th>\n",
       "      <td>-0.0028</td>\n",
       "      <td>0.0383</td>\n",
       "      <td>0.9428</td>\n",
       "      <td>3</td>\n",
       "      <td>20000</td>\n",
       "      <td>death</td>\n",
       "      <td>logisticRegression-death</td>\n",
       "      <td>0.0013</td>\n",
       "      <td>0.0026</td>\n",
       "      <td>0.0163</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>300383</th>\n",
       "      <td>-0.0048</td>\n",
       "      <td>0.0382</td>\n",
       "      <td>0.9006</td>\n",
       "      <td>3</td>\n",
       "      <td>20000</td>\n",
       "      <td>death</td>\n",
       "      <td>logisticRegression-death</td>\n",
       "      <td>0.0013</td>\n",
       "      <td>0.0026</td>\n",
       "      <td>0.0161</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>300384</th>\n",
       "      <td>-0.0315</td>\n",
       "      <td>0.0385</td>\n",
       "      <td>0.4127</td>\n",
       "      <td>3</td>\n",
       "      <td>20000</td>\n",
       "      <td>death</td>\n",
       "      <td>logisticRegression-death</td>\n",
       "      <td>0.0013</td>\n",
       "      <td>0.0026</td>\n",
       "      <td>0.0155</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>300385</th>\n",
       "      <td>0.0375</td>\n",
       "      <td>0.0383</td>\n",
       "      <td>0.3269</td>\n",
       "      <td>3</td>\n",
       "      <td>20000</td>\n",
       "      <td>death</td>\n",
       "      <td>logisticRegression-death</td>\n",
       "      <td>0.0013</td>\n",
       "      <td>0.0026</td>\n",
       "      <td>0.0158</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>300386</th>\n",
       "      <td>-0.0645</td>\n",
       "      <td>0.0384</td>\n",
       "      <td>0.0927</td>\n",
       "      <td>3</td>\n",
       "      <td>20000</td>\n",
       "      <td>death</td>\n",
       "      <td>logisticRegression-death</td>\n",
       "      <td>0.0013</td>\n",
       "      <td>0.0026</td>\n",
       "      <td>0.0148</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>300387</th>\n",
       "      <td>-0.0016</td>\n",
       "      <td>0.0381</td>\n",
       "      <td>0.9659</td>\n",
       "      <td>3</td>\n",
       "      <td>20000</td>\n",
       "      <td>death</td>\n",
       "      <td>logisticRegression-death</td>\n",
       "      <td>0.0013</td>\n",
       "      <td>0.0026</td>\n",
       "      <td>0.0147</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>300388</th>\n",
       "      <td>-0.0522</td>\n",
       "      <td>0.0383</td>\n",
       "      <td>0.1731</td>\n",
       "      <td>3</td>\n",
       "      <td>20000</td>\n",
       "      <td>death</td>\n",
       "      <td>logisticRegression-death</td>\n",
       "      <td>0.0013</td>\n",
       "      <td>0.0026</td>\n",
       "      <td>0.0139</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>300389</th>\n",
       "      <td>0.0564</td>\n",
       "      <td>0.0384</td>\n",
       "      <td>0.1420</td>\n",
       "      <td>3</td>\n",
       "      <td>20000</td>\n",
       "      <td>death</td>\n",
       "      <td>logisticRegression-death</td>\n",
       "      <td>0.0013</td>\n",
       "      <td>0.0026</td>\n",
       "      <td>0.0144</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>300390</th>\n",
       "      <td>0.0261</td>\n",
       "      <td>0.0384</td>\n",
       "      <td>0.4965</td>\n",
       "      <td>3</td>\n",
       "      <td>20000</td>\n",
       "      <td>death</td>\n",
       "      <td>logisticRegression-death</td>\n",
       "      <td>0.0013</td>\n",
       "      <td>0.0026</td>\n",
       "      <td>0.0145</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>300391</th>\n",
       "      <td>-0.0550</td>\n",
       "      <td>0.0380</td>\n",
       "      <td>0.1483</td>\n",
       "      <td>3</td>\n",
       "      <td>20000</td>\n",
       "      <td>death</td>\n",
       "      <td>logisticRegression-death</td>\n",
       "      <td>0.0013</td>\n",
       "      <td>0.0026</td>\n",
       "      <td>0.0138</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>300392</th>\n",
       "      <td>-0.0062</td>\n",
       "      <td>0.0385</td>\n",
       "      <td>0.8723</td>\n",
       "      <td>3</td>\n",
       "      <td>20000</td>\n",
       "      <td>death</td>\n",
       "      <td>logisticRegression-death</td>\n",
       "      <td>0.0013</td>\n",
       "      <td>0.0026</td>\n",
       "      <td>0.0135</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>300393</th>\n",
       "      <td>-0.0530</td>\n",
       "      <td>0.0384</td>\n",
       "      <td>0.1669</td>\n",
       "      <td>3</td>\n",
       "      <td>20000</td>\n",
       "      <td>death</td>\n",
       "      <td>logisticRegression-death</td>\n",
       "      <td>0.0013</td>\n",
       "      <td>0.0026</td>\n",
       "      <td>0.0128</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>300394</th>\n",
       "      <td>-0.0444</td>\n",
       "      <td>0.0386</td>\n",
       "      <td>0.2501</td>\n",
       "      <td>3</td>\n",
       "      <td>20000</td>\n",
       "      <td>death</td>\n",
       "      <td>logisticRegression-death</td>\n",
       "      <td>0.0013</td>\n",
       "      <td>0.0026</td>\n",
       "      <td>0.0122</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>300395</th>\n",
       "      <td>0.0487</td>\n",
       "      <td>0.0386</td>\n",
       "      <td>0.2071</td>\n",
       "      <td>3</td>\n",
       "      <td>20000</td>\n",
       "      <td>death</td>\n",
       "      <td>logisticRegression-death</td>\n",
       "      <td>0.0013</td>\n",
       "      <td>0.0026</td>\n",
       "      <td>0.0126</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>300396</th>\n",
       "      <td>0.0251</td>\n",
       "      <td>0.0383</td>\n",
       "      <td>0.5122</td>\n",
       "      <td>3</td>\n",
       "      <td>20000</td>\n",
       "      <td>death</td>\n",
       "      <td>logisticRegression-death</td>\n",
       "      <td>0.0013</td>\n",
       "      <td>0.0026</td>\n",
       "      <td>0.0127</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>300397</th>\n",
       "      <td>0.0821</td>\n",
       "      <td>0.0386</td>\n",
       "      <td>0.0333</td>\n",
       "      <td>3</td>\n",
       "      <td>20000</td>\n",
       "      <td>death</td>\n",
       "      <td>logisticRegression-death</td>\n",
       "      <td>0.0013</td>\n",
       "      <td>0.0026</td>\n",
       "      <td>0.0134</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>300398</th>\n",
       "      <td>-0.0283</td>\n",
       "      <td>0.0387</td>\n",
       "      <td>0.4648</td>\n",
       "      <td>3</td>\n",
       "      <td>20000</td>\n",
       "      <td>death</td>\n",
       "      <td>logisticRegression-death</td>\n",
       "      <td>0.0013</td>\n",
       "      <td>0.0026</td>\n",
       "      <td>0.0130</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>300399</th>\n",
       "      <td>0.0506</td>\n",
       "      <td>0.0381</td>\n",
       "      <td>0.1838</td>\n",
       "      <td>3</td>\n",
       "      <td>20000</td>\n",
       "      <td>death</td>\n",
       "      <td>logisticRegression-death</td>\n",
       "      <td>0.0013</td>\n",
       "      <td>0.0026</td>\n",
       "      <td>0.0134</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           reg     se  pvalue  duration  sampleSize outcome  \\\n",
       "288350  0.0071 0.0419  0.8651         3       20000   death   \n",
       "288351  0.0336 0.0412  0.4144         3       20000   death   \n",
       "288352  0.0162 0.0418  0.6992         3       20000   death   \n",
       "288353 -0.0166 0.0420  0.6919         3       20000   death   \n",
       "288354  0.0006 0.0418  0.9895         3       20000   death   \n",
       "288355 -0.0100 0.0417  0.8101         3       20000   death   \n",
       "288356 -0.0221 0.0420  0.5980         3       20000   death   \n",
       "288357 -0.0051 0.0414  0.9027         3       20000   death   \n",
       "288358  0.0099 0.0417  0.8129         3       20000   death   \n",
       "288359 -0.0002 0.0419  0.9969         3       20000   death   \n",
       "288360  0.0092 0.0414  0.8241         3       20000   death   \n",
       "288361  0.0120 0.0411  0.7710         3       20000   death   \n",
       "288362  0.0150 0.0417  0.7191         3       20000   death   \n",
       "288363 -0.0419 0.0419  0.3179         3       20000   death   \n",
       "288364  0.0113 0.0419  0.7866         3       20000   death   \n",
       "288365 -0.0439 0.0423  0.2993         3       20000   death   \n",
       "288366  0.0203 0.0418  0.6268         3       20000   death   \n",
       "288367 -0.0026 0.0418  0.9510         3       20000   death   \n",
       "288368  0.0077 0.0418  0.8543         3       20000   death   \n",
       "288369 -0.0241 0.0420  0.5671         3       20000   death   \n",
       "288370  0.0566 0.0413  0.1709         3       20000   death   \n",
       "288371  0.0061 0.0421  0.8856         3       20000   death   \n",
       "288372 -0.0329 0.0425  0.4394         3       20000   death   \n",
       "288373 -0.0547 0.0421  0.1939         3       20000   death   \n",
       "288374  0.0509 0.0417  0.2217         3       20000   death   \n",
       "288375  0.0647 0.0417  0.1211         3       20000   death   \n",
       "288376  0.0508 0.0418  0.2242         3       20000   death   \n",
       "288377  0.0373 0.0416  0.3700         3       20000   death   \n",
       "288378 -0.0505 0.0426  0.2358         3       20000   death   \n",
       "288379  0.1120 0.0412  0.0066         3       20000   death   \n",
       "288380  0.0315 0.0416  0.4490         3       20000   death   \n",
       "288381  0.0486 0.0419  0.2466         3       20000   death   \n",
       "288382  0.0068 0.0413  0.8699         3       20000   death   \n",
       "288383 -0.0153 0.0419  0.7151         3       20000   death   \n",
       "288384  0.0530 0.0418  0.2047         3       20000   death   \n",
       "288385  0.0739 0.0418  0.0769         3       20000   death   \n",
       "288386  0.0101 0.0416  0.8087         3       20000   death   \n",
       "288387  0.1118 0.0417  0.0073         3       20000   death   \n",
       "288388 -0.0167 0.0423  0.6928         3       20000   death   \n",
       "288389 -0.0316 0.0416  0.4473         3       20000   death   \n",
       "288390 -0.0158 0.0418  0.7049         3       20000   death   \n",
       "288391 -0.0176 0.0416  0.6721         3       20000   death   \n",
       "288392  0.0111 0.0420  0.7915         3       20000   death   \n",
       "288393  0.0190 0.0420  0.6508         3       20000   death   \n",
       "288394 -0.0001 0.0414  0.9977         3       20000   death   \n",
       "288395  0.0184 0.0412  0.6549         3       20000   death   \n",
       "288396  0.0060 0.0417  0.8851         3       20000   death   \n",
       "288397 -0.0181 0.0414  0.6616         3       20000   death   \n",
       "288398 -0.0311 0.0415  0.4533         3       20000   death   \n",
       "288399 -0.0162 0.0420  0.6998         3       20000   death   \n",
       "300350  0.0499 0.0383  0.1932         3       20000   death   \n",
       "300351  0.0318 0.0384  0.4077         3       20000   death   \n",
       "300352  0.0630 0.0381  0.0984         3       20000   death   \n",
       "300353  0.0411 0.0385  0.2855         3       20000   death   \n",
       "300354  0.0635 0.0382  0.0961         3       20000   death   \n",
       "300355  0.0407 0.0386  0.2914         3       20000   death   \n",
       "300356  0.0673 0.0382  0.0779         3       20000   death   \n",
       "300357  0.0261 0.0382  0.4949         3       20000   death   \n",
       "300358  0.0530 0.0383  0.1659         3       20000   death   \n",
       "300359  0.0152 0.0385  0.6922         3       20000   death   \n",
       "300360  0.0648 0.0381  0.0895         3       20000   death   \n",
       "300361  0.0491 0.0386  0.2033         3       20000   death   \n",
       "300362  0.0658 0.0383  0.0855         3       20000   death   \n",
       "300363  0.0447 0.0387  0.2478         3       20000   death   \n",
       "300364  0.0583 0.0381  0.1262         3       20000   death   \n",
       "300365  0.0405 0.0385  0.2930         3       20000   death   \n",
       "300366  0.0526 0.0383  0.1693         3       20000   death   \n",
       "300367  0.0420 0.0385  0.2748         3       20000   death   \n",
       "300368  0.0700 0.0382  0.0666         3       20000   death   \n",
       "300369  0.0349 0.0385  0.3650         3       20000   death   \n",
       "300370 -0.0025 0.0385  0.9478         3       20000   death   \n",
       "300371 -0.0025 0.0387  0.9480         3       20000   death   \n",
       "300372  0.0283 0.0381  0.4572         3       20000   death   \n",
       "300373  0.0516 0.0383  0.1784         3       20000   death   \n",
       "300374 -0.0632 0.0384  0.0996         3       20000   death   \n",
       "300375  0.0494 0.0382  0.1955         3       20000   death   \n",
       "300376 -0.0656 0.0386  0.0893         3       20000   death   \n",
       "300377  0.0361 0.0386  0.3487         3       20000   death   \n",
       "300378 -0.0618 0.0386  0.1093         3       20000   death   \n",
       "300379  0.0134 0.0387  0.7298         3       20000   death   \n",
       "300380 -0.0719 0.0384  0.0613         3       20000   death   \n",
       "300381  0.0275 0.0381  0.4713         3       20000   death   \n",
       "300382 -0.0028 0.0383  0.9428         3       20000   death   \n",
       "300383 -0.0048 0.0382  0.9006         3       20000   death   \n",
       "300384 -0.0315 0.0385  0.4127         3       20000   death   \n",
       "300385  0.0375 0.0383  0.3269         3       20000   death   \n",
       "300386 -0.0645 0.0384  0.0927         3       20000   death   \n",
       "300387 -0.0016 0.0381  0.9659         3       20000   death   \n",
       "300388 -0.0522 0.0383  0.1731         3       20000   death   \n",
       "300389  0.0564 0.0384  0.1420         3       20000   death   \n",
       "300390  0.0261 0.0384  0.4965         3       20000   death   \n",
       "300391 -0.0550 0.0380  0.1483         3       20000   death   \n",
       "300392 -0.0062 0.0385  0.8723         3       20000   death   \n",
       "300393 -0.0530 0.0384  0.1669         3       20000   death   \n",
       "300394 -0.0444 0.0386  0.2501         3       20000   death   \n",
       "300395  0.0487 0.0386  0.2071         3       20000   death   \n",
       "300396  0.0251 0.0383  0.5122         3       20000   death   \n",
       "300397  0.0821 0.0386  0.0333         3       20000   death   \n",
       "300398 -0.0283 0.0387  0.4648         3       20000   death   \n",
       "300399  0.0506 0.0381  0.1838         3       20000   death   \n",
       "\n",
       "                        analysis  dementiaRisk  cvRisk  runMeanReg  \n",
       "288350  logisticRegression-death        0.0013  0.0026      0.0071  \n",
       "288351  logisticRegression-death        0.0013  0.0026      0.0204  \n",
       "288352  logisticRegression-death        0.0013  0.0026      0.0190  \n",
       "288353  logisticRegression-death        0.0013  0.0026      0.0101  \n",
       "288354  logisticRegression-death        0.0013  0.0026      0.0082  \n",
       "288355  logisticRegression-death        0.0013  0.0026      0.0051  \n",
       "288356  logisticRegression-death        0.0013  0.0026      0.0012  \n",
       "288357  logisticRegression-death        0.0013  0.0026      0.0005  \n",
       "288358  logisticRegression-death        0.0013  0.0026      0.0015  \n",
       "288359  logisticRegression-death        0.0013  0.0026      0.0013  \n",
       "288360  logisticRegression-death        0.0013  0.0026      0.0020  \n",
       "288361  logisticRegression-death        0.0013  0.0026      0.0029  \n",
       "288362  logisticRegression-death        0.0013  0.0026      0.0038  \n",
       "288363  logisticRegression-death        0.0013  0.0026      0.0005  \n",
       "288364  logisticRegression-death        0.0013  0.0026      0.0013  \n",
       "288365  logisticRegression-death        0.0013  0.0026     -0.0016  \n",
       "288366  logisticRegression-death        0.0013  0.0026     -0.0003  \n",
       "288367  logisticRegression-death        0.0013  0.0026     -0.0004  \n",
       "288368  logisticRegression-death        0.0013  0.0026      0.0000  \n",
       "288369  logisticRegression-death        0.0013  0.0026     -0.0012  \n",
       "288370  logisticRegression-death        0.0013  0.0026      0.0016  \n",
       "288371  logisticRegression-death        0.0013  0.0026      0.0018  \n",
       "288372  logisticRegression-death        0.0013  0.0026      0.0003  \n",
       "288373  logisticRegression-death        0.0013  0.0026     -0.0020  \n",
       "288374  logisticRegression-death        0.0013  0.0026      0.0001  \n",
       "288375  logisticRegression-death        0.0013  0.0026      0.0026  \n",
       "288376  logisticRegression-death        0.0013  0.0026      0.0044  \n",
       "288377  logisticRegression-death        0.0013  0.0026      0.0055  \n",
       "288378  logisticRegression-death        0.0013  0.0026      0.0036  \n",
       "288379  logisticRegression-death        0.0013  0.0026      0.0072  \n",
       "288380  logisticRegression-death        0.0013  0.0026      0.0080  \n",
       "288381  logisticRegression-death        0.0013  0.0026      0.0093  \n",
       "288382  logisticRegression-death        0.0013  0.0026      0.0092  \n",
       "288383  logisticRegression-death        0.0013  0.0026      0.0085  \n",
       "288384  logisticRegression-death        0.0013  0.0026      0.0098  \n",
       "288385  logisticRegression-death        0.0013  0.0026      0.0115  \n",
       "288386  logisticRegression-death        0.0013  0.0026      0.0115  \n",
       "288387  logisticRegression-death        0.0013  0.0026      0.0141  \n",
       "288388  logisticRegression-death        0.0013  0.0026      0.0133  \n",
       "288389  logisticRegression-death        0.0013  0.0026      0.0122  \n",
       "288390  logisticRegression-death        0.0013  0.0026      0.0115  \n",
       "288391  logisticRegression-death        0.0013  0.0026      0.0108  \n",
       "288392  logisticRegression-death        0.0013  0.0026      0.0108  \n",
       "288393  logisticRegression-death        0.0013  0.0026      0.0110  \n",
       "288394  logisticRegression-death        0.0013  0.0026      0.0108  \n",
       "288395  logisticRegression-death        0.0013  0.0026      0.0110  \n",
       "288396  logisticRegression-death        0.0013  0.0026      0.0108  \n",
       "288397  logisticRegression-death        0.0013  0.0026      0.0102  \n",
       "288398  logisticRegression-death        0.0013  0.0026      0.0094  \n",
       "288399  logisticRegression-death        0.0013  0.0026      0.0089  \n",
       "300350  logisticRegression-death        0.0013  0.0026      0.0097  \n",
       "300351  logisticRegression-death        0.0013  0.0026      0.0101  \n",
       "300352  logisticRegression-death        0.0013  0.0026      0.0111  \n",
       "300353  logisticRegression-death        0.0013  0.0026      0.0117  \n",
       "300354  logisticRegression-death        0.0013  0.0026      0.0126  \n",
       "300355  logisticRegression-death        0.0013  0.0026      0.0131  \n",
       "300356  logisticRegression-death        0.0013  0.0026      0.0141  \n",
       "300357  logisticRegression-death        0.0013  0.0026      0.0143  \n",
       "300358  logisticRegression-death        0.0013  0.0026      0.0149  \n",
       "300359  logisticRegression-death        0.0013  0.0026      0.0149  \n",
       "300360  logisticRegression-death        0.0013  0.0026      0.0158  \n",
       "300361  logisticRegression-death        0.0013  0.0026      0.0163  \n",
       "300362  logisticRegression-death        0.0013  0.0026      0.0171  \n",
       "300363  logisticRegression-death        0.0013  0.0026      0.0175  \n",
       "300364  logisticRegression-death        0.0013  0.0026      0.0181  \n",
       "300365  logisticRegression-death        0.0013  0.0026      0.0185  \n",
       "300366  logisticRegression-death        0.0013  0.0026      0.0190  \n",
       "300367  logisticRegression-death        0.0013  0.0026      0.0193  \n",
       "300368  logisticRegression-death        0.0013  0.0026      0.0201  \n",
       "300369  logisticRegression-death        0.0013  0.0026      0.0203  \n",
       "300370  logisticRegression-death        0.0013  0.0026      0.0200  \n",
       "300371  logisticRegression-death        0.0013  0.0026      0.0196  \n",
       "300372  logisticRegression-death        0.0013  0.0026      0.0198  \n",
       "300373  logisticRegression-death        0.0013  0.0026      0.0202  \n",
       "300374  logisticRegression-death        0.0013  0.0026      0.0191  \n",
       "300375  logisticRegression-death        0.0013  0.0026      0.0195  \n",
       "300376  logisticRegression-death        0.0013  0.0026      0.0184  \n",
       "300377  logisticRegression-death        0.0013  0.0026      0.0186  \n",
       "300378  logisticRegression-death        0.0013  0.0026      0.0176  \n",
       "300379  logisticRegression-death        0.0013  0.0026      0.0175  \n",
       "300380  logisticRegression-death        0.0013  0.0026      0.0164  \n",
       "300381  logisticRegression-death        0.0013  0.0026      0.0166  \n",
       "300382  logisticRegression-death        0.0013  0.0026      0.0163  \n",
       "300383  logisticRegression-death        0.0013  0.0026      0.0161  \n",
       "300384  logisticRegression-death        0.0013  0.0026      0.0155  \n",
       "300385  logisticRegression-death        0.0013  0.0026      0.0158  \n",
       "300386  logisticRegression-death        0.0013  0.0026      0.0148  \n",
       "300387  logisticRegression-death        0.0013  0.0026      0.0147  \n",
       "300388  logisticRegression-death        0.0013  0.0026      0.0139  \n",
       "300389  logisticRegression-death        0.0013  0.0026      0.0144  \n",
       "300390  logisticRegression-death        0.0013  0.0026      0.0145  \n",
       "300391  logisticRegression-death        0.0013  0.0026      0.0138  \n",
       "300392  logisticRegression-death        0.0013  0.0026      0.0135  \n",
       "300393  logisticRegression-death        0.0013  0.0026      0.0128  \n",
       "300394  logisticRegression-death        0.0013  0.0026      0.0122  \n",
       "300395  logisticRegression-death        0.0013  0.0026      0.0126  \n",
       "300396  logisticRegression-death        0.0013  0.0026      0.0127  \n",
       "300397  logisticRegression-death        0.0013  0.0026      0.0134  \n",
       "300398  logisticRegression-death        0.0013  0.0026      0.0130  \n",
       "300399  logisticRegression-death        0.0013  0.0026      0.0134  "
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results.loc[ (results[\"outcome\"]==outcomes[0]) & \n",
    "                    (results[\"sampleSize\"]==sampleSizes[7]) &\n",
    "                    (results[\"dementiaRisk\"]==dementiaRisks[2]) & \n",
    "                    (results[\"cvRisk\"]==cvRisks[2]) &\n",
    "                    (results[\"duration\"]==durations[0]) ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "bbf5de34",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array(['death', 'deathstroke-mi-dementia-', 'deathstroke-mi-',\n",
       "        '_qalys-sum', '_gcp-mean', '_gcp-last'], dtype=object),\n",
       " array([ 3,  5, 10, 15, 20]),\n",
       " array([  100,   200,   500,  1000,  5000, 10000, 15000, 20000]),\n",
       " array([1.16760305e-06, 8.19374349e-04, 2.61911059e-03, 6.09125141e-03,\n",
       "        1.32184646e-02]),\n",
       " array([2.48458399e-08, 1.85764173e-04, 1.29172709e-03, 5.87051016e-03,\n",
       "        2.57394432e-02]))"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#just a reminder of the values, unsure about the source of nan at the end\n",
    "outcomes,durations,sampleSizes,cvRisks,dementiaRisks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "4108ecd4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20000\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#note: any plots that include less than 100 data points is due to regression returning nan \n",
    "#note: I have not implemented anything yet on dealing with nan, eg resubmitting the calculation\n",
    "#note: the single dot at the end is just for validation of my running average\n",
    "\n",
    "#for outcome in outcomes: #plot for all outcomes\n",
    "for outcome in [outcomes[0]]:   #set a specific outcome\n",
    "    #for duration in durations: #plot for all durations\n",
    "    for duration in [durations[0]]: \n",
    "        #for sampleSize in sampleSizes: #plot for all sample sizes\n",
    "        for sampleSize in [sampleSizes[7]]:\n",
    "            print(sampleSize)\n",
    "            #for iCvRisk in range(len(cvRisks)): #plot for all cv risks\n",
    "            for iCvRisk in [2]: #set a specific risk, 0-4            \n",
    "                #for iDementiaRisk in range(len(dementiaRisks)): #plot for all dementia risks\n",
    "                for iDementiaRisk in [2]: #set a specific dementia risk, 0-4\n",
    "                    plotData=results.loc[ #get all relevant data\n",
    "                    (results[\"outcome\"]==outcome) & \n",
    "                    (results[\"sampleSize\"]==sampleSize) &\n",
    "                    (results[\"dementiaRisk\"]==dementiaRisks[iDementiaRisk]) & \n",
    "                    (results[\"cvRisk\"]==cvRisks[iCvRisk]) &\n",
    "                    (results[\"duration\"]==duration), \"runMeanReg\"].copy()\n",
    "                    plt.scatter(range(len(plotData)),plotData)\n",
    "                    plt.scatter(99,meanReg[f\"{outcome},{duration},{sampleSize}\"][iCvRisk,iDementiaRisk])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9578b30",
   "metadata": {},
   "outputs": [],
   "source": [
    "for outcome in [outcomes[0]]:    #change to outcomes in order to see all heatmaps associated with all outcomes\n",
    "    for duration in durations:\n",
    "        for sampleSize in [sampleSizes[0]]:  #change to sampleSizes to see heatmaps associated with all sample sizes\n",
    "            print(f\"{outcomes[0]},{durations[0]},{sampleSizes[0]}\")\n",
    "            dataForPlot=meanReg[f\"{outcomes[0]},{durations[0]},{sampleSizes[0]}\"]\n",
    "            fig, ax = plt.subplots()\n",
    "            im = ax.imshow(dataForPlot)\n",
    "\n",
    "            # Show all ticks and label them with the respective list entries\n",
    "            ax.set_xticks(np.arange(len(cvRisks)), labels=cvRisks)\n",
    "            ax.set_yticks(np.arange(len(dementiaRisks)), labels=dementiaRisks)\n",
    "            ax.set(xlabel='cv risk', ylabel='dementia risk')\n",
    "\n",
    "            # Rotate the tick labels and set their alignment.\n",
    "            plt.setp(ax.get_xticklabels(), rotation=45, ha=\"right\",\n",
    "            rotation_mode=\"anchor\")\n",
    "\n",
    "            cbar = ax.figure.colorbar(im, ax=ax)\n",
    "            cbar.ax.set_ylabel(\"mean effect size\", rotation=-90, va=\"bottom\")\n",
    "\n",
    "            ax.set_title(\"mean effect size\")\n",
    "            fig.tight_layout()\n",
    "            plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9de6dc95",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "microsimKernel",
   "language": "python",
   "name": "microsimkernel"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
